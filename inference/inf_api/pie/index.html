<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>inference.pie API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>inference.pie</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Objects for defining signal &amp; probability models
from .signalmodel import SignalModel
from .realparam import RealParam

# Objects for defining &amp; using Predictors
from .predictor import PredictorSet, DataError

# Objects for defining &amp; using inferences
from .inference_base import InferenceError
from .chisqr import ChisqrInference
from .maxlike import MaxLikeInference
from .bayes import BayesianInference
from .gaussian import SampledGaussian

from .logger import pielog

__version__ = &#39;0.5&#39;

__all__ = [&#34;pielog&#34;, &#34;RealParam&#34;, &#34;SignalModel&#34;,
           &#34;InferenceError&#34;, &#34;PredictorSet&#34;, &#34;DataError&#34;,
           &#34;ChisqrInference&#34;, &#34;MaxLikeInference&#34;, &#34;BayesianInference&#34;,
           &#34;SampledGaussian&#34;]</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="inference.pie.autoname" href="autoname.html">inference.pie.autoname</a></code></dt>
<dd>
<div class="desc"><p>Automatically named descriptors …</p></div>
</dd>
<dt><code class="name"><a title="inference.pie.bayes" href="bayes.html">inference.pie.bayes</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="inference.pie.chisqr" href="chisqr.html">inference.pie.chisqr</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="inference.pie.containers" href="containers.html">inference.pie.containers</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="inference.pie.gaussian" href="gaussian.html">inference.pie.gaussian</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="inference.pie.inference_base" href="inference_base.html">inference.pie.inference_base</a></code></dt>
<dd>
<div class="desc"><p>Utilities and base class for inferences.</p></div>
</dd>
<dt><code class="name"><a title="inference.pie.logger" href="logger.html">inference.pie.logger</a></code></dt>
<dd>
<div class="desc"><p>logger:
A stream logger for PIE, logging to stderr.</p></div>
</dd>
<dt><code class="name"><a title="inference.pie.maxlike" href="maxlike.html">inference.pie.maxlike</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="inference.pie.param" href="param.html">inference.pie.param</a></code></dt>
<dd>
<div class="desc"><p>param.py …</p></div>
</dd>
<dt><code class="name"><a title="inference.pie.predictor" href="predictor.html">inference.pie.predictor</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="inference.pie.realparam" href="realparam.html">inference.pie.realparam</a></code></dt>
<dd>
<div class="desc"><p>Real-valued (i.e., float-valued) parameters.</p></div>
</dd>
<dt><code class="name"><a title="inference.pie.setup" href="setup.html">inference.pie.setup</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="inference.pie.signalmodel" href="signalmodel.html">inference.pie.signalmodel</a></code></dt>
<dd>
<div class="desc"><p>Parameterized signal model base class.</p></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="inference.pie.BayesianInference"><code class="flex name class">
<span>class <span class="ident">BayesianInference</span></span>
</code></dt>
<dd>
<div class="desc"><p>Base class for Bayesian inferences made using the product of
a prior distribution for parameters and a likelihood function.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BayesianInference(Inference):
    &#34;&#34;&#34;Base class for Bayesian inferences made using the product of
    a prior distribution for parameters and a likelihood function.&#34;&#34;&#34;

    # Larger values of prior*likelihood are preferred!
    extremize = maximize

    # Set default minimization method and tolerance
    min_method = &#39;powell&#39;
    min_tol = 1.e-6

    # There is intentionally no default MCMC method; a good method
    # must be problem-specific.
    MCMC_method = None

    # def prior(self):
    # We could put a prior/logprior prototype here for users to override,
    # but if they define a prior in their SignalModel classes, it won&#39;t
    # override the prototype if BayesianInference is the first base class
    # in their inference class.

    def score(self):
        &#34;&#34;&#34;
        The function to optimize in a fit---here the log(prior*likelihood).

        Note that a rigorous Bayesian &#39;optimum&#39; requires specification of
        a utility (or loss) function; the decision-theoretic optimum maximizes
        the expected utility.
        &#34;&#34;&#34;
        self._log_like = 0.
        for name in self.predictor_names:
            self._log_like += getattr(self, name).log_like()
        self._log_prior = self.log_prior()
        return self._log_like + self._log_prior

    def logp(self):
        &#34;&#34;&#34;
        The log &#39;posterior&#39; (i.e., prior*likelihood, unnormalized) for the
        current parameter values.
        &#34;&#34;&#34;
        return self.score()

    def _logp_func(self, args):
        &#34;&#34;&#34;
        The log posterior (prior*likelihood), implemented as a function of
        an array (or other sequence) of values of varying parameters.

        This is intended for use by algorithms that require a function with a
        sequence argument, e.g., the observed information algorithm.
        &#34;&#34;&#34;
        # *** Note this changes *all* varying parameters, even those whose
        # actual value is not changed.  See the note for _score in inference.py.
        for param, val in zip(self.varying_params, args):
            param.set_value(val)
        return self.score()

    def obs_info(self, steps=None, dlogp=1., n=3, err=False):
        &#34;&#34;&#34;
        Calculated the observed information matrix for varying parameters,
        assuming their current values correspond to a mode (at which a fit
        has already been evaluated).
        &#34;&#34;&#34;
        # *** Expand docstring.
        # Treat the current state as the mode.
        logp_max = self._log_like + self._log_prior
        mode = []
        for param in self.varying_params:
            mode.append(param.get_value())
        # Find scales for the parameters that change logp by dlogp.
        # Start with the steps arg if provided; otherwise use current
        # varying parameter scales.
        if steps is None:
            deltas = []
            for param in self.varying_params:
                deltas.append(param.delta)
        else:
            deltas = steps
        deltas = dllsteps(self._logp_func, mode, deltas, dlogp, logp_max)
        # Use those step sizes for estimating the observed info matrix.
        info, ierr = obsinfo(self._logp_func, mode, deltas, logp_max, niter=n)
        if err:
            return info, ierr
        else:
            return info

    def marg(self):
        &#34;&#34;&#34;
        Return the log integral of prior*likelihood, with the integral
        performed over varying parameters via adaptive quadrature.
        &#34;&#34;&#34;
        raise NotImplementedError

    def laplace(self):
        &#34;&#34;&#34;
        Return an approximation to the log of the integral of the
        prior*likelihood over varying parameters, calculated using the Laplace 
        approximation, i.e., by maximizing and multiplying by the determinant
        of the information matrix.
        &#34;&#34;&#34;
        # *** Enable this on a grid.
        raise NotImplementedError

    def set_proposer(self):
        &#34;&#34;&#34;Define the proposal distribution for MCMC posterior sampling.&#34;&#34;&#34;
        raise NotImplementedError

    def proposal(self):
        &#34;&#34;&#34;Return a candidate new state for the Markov chain.&#34;&#34;&#34;
        raise NotImplementedError

    def MH_step(self):
        &#34;&#34;&#34;Perform a single step of the Metropolis-Hastings sampler.&#34;&#34;&#34;
        raise NotImplementedError

    def MH_steps(self, n, thin=None):
        &#34;&#34;&#34;Perform n steps of the Metropolis-Hastings sampler.  If thin=t is
        provided, store a thinned version of the resulting time series,
        keeping only every t&#39;th sample.&#34;&#34;&#34;
        raise NotImplementedError</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="inference.pie.inference_base.Inference" href="inference_base.html#inference.pie.inference_base.Inference">Inference</a></li>
<li><a title="inference.pie.autoname.HasAutoNamed" href="autoname.html#inference.pie.autoname.HasAutoNamed">HasAutoNamed</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="inference.pie.BayesianInference.MCMC_method"><code class="name">var <span class="ident">MCMC_method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="inference.pie.BayesianInference.extremize"><code class="name">var <span class="ident">extremize</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="inference.pie.BayesianInference.min_method"><code class="name">var <span class="ident">min_method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="inference.pie.BayesianInference.min_tol"><code class="name">var <span class="ident">min_tol</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="inference.pie.BayesianInference.MH_step"><code class="name flex">
<span>def <span class="ident">MH_step</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform a single step of the Metropolis-Hastings sampler.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def MH_step(self):
    &#34;&#34;&#34;Perform a single step of the Metropolis-Hastings sampler.&#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="inference.pie.BayesianInference.MH_steps"><code class="name flex">
<span>def <span class="ident">MH_steps</span></span>(<span>self, n, thin=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform n steps of the Metropolis-Hastings sampler.
If thin=t is
provided, store a thinned version of the resulting time series,
keeping only every t'th sample.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def MH_steps(self, n, thin=None):
    &#34;&#34;&#34;Perform n steps of the Metropolis-Hastings sampler.  If thin=t is
    provided, store a thinned version of the resulting time series,
    keeping only every t&#39;th sample.&#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="inference.pie.BayesianInference.laplace"><code class="name flex">
<span>def <span class="ident">laplace</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return an approximation to the log of the integral of the
prior*likelihood over varying parameters, calculated using the Laplace
approximation, i.e., by maximizing and multiplying by the determinant
of the information matrix.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def laplace(self):
    &#34;&#34;&#34;
    Return an approximation to the log of the integral of the
    prior*likelihood over varying parameters, calculated using the Laplace 
    approximation, i.e., by maximizing and multiplying by the determinant
    of the information matrix.
    &#34;&#34;&#34;
    # *** Enable this on a grid.
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="inference.pie.BayesianInference.logp"><code class="name flex">
<span>def <span class="ident">logp</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>The log 'posterior' (i.e., prior*likelihood, unnormalized) for the
current parameter values.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def logp(self):
    &#34;&#34;&#34;
    The log &#39;posterior&#39; (i.e., prior*likelihood, unnormalized) for the
    current parameter values.
    &#34;&#34;&#34;
    return self.score()</code></pre>
</details>
</dd>
<dt id="inference.pie.BayesianInference.marg"><code class="name flex">
<span>def <span class="ident">marg</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the log integral of prior*likelihood, with the integral
performed over varying parameters via adaptive quadrature.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def marg(self):
    &#34;&#34;&#34;
    Return the log integral of prior*likelihood, with the integral
    performed over varying parameters via adaptive quadrature.
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="inference.pie.BayesianInference.obs_info"><code class="name flex">
<span>def <span class="ident">obs_info</span></span>(<span>self, steps=None, dlogp=1.0, n=3, err=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculated the observed information matrix for varying parameters,
assuming their current values correspond to a mode (at which a fit
has already been evaluated).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def obs_info(self, steps=None, dlogp=1., n=3, err=False):
    &#34;&#34;&#34;
    Calculated the observed information matrix for varying parameters,
    assuming their current values correspond to a mode (at which a fit
    has already been evaluated).
    &#34;&#34;&#34;
    # *** Expand docstring.
    # Treat the current state as the mode.
    logp_max = self._log_like + self._log_prior
    mode = []
    for param in self.varying_params:
        mode.append(param.get_value())
    # Find scales for the parameters that change logp by dlogp.
    # Start with the steps arg if provided; otherwise use current
    # varying parameter scales.
    if steps is None:
        deltas = []
        for param in self.varying_params:
            deltas.append(param.delta)
    else:
        deltas = steps
    deltas = dllsteps(self._logp_func, mode, deltas, dlogp, logp_max)
    # Use those step sizes for estimating the observed info matrix.
    info, ierr = obsinfo(self._logp_func, mode, deltas, logp_max, niter=n)
    if err:
        return info, ierr
    else:
        return info</code></pre>
</details>
</dd>
<dt id="inference.pie.BayesianInference.proposal"><code class="name flex">
<span>def <span class="ident">proposal</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a candidate new state for the Markov chain.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def proposal(self):
    &#34;&#34;&#34;Return a candidate new state for the Markov chain.&#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="inference.pie.BayesianInference.score"><code class="name flex">
<span>def <span class="ident">score</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>The function to optimize in a fit&mdash;here the log(prior*likelihood).</p>
<p>Note that a rigorous Bayesian 'optimum' requires specification of
a utility (or loss) function; the decision-theoretic optimum maximizes
the expected utility.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def score(self):
    &#34;&#34;&#34;
    The function to optimize in a fit---here the log(prior*likelihood).

    Note that a rigorous Bayesian &#39;optimum&#39; requires specification of
    a utility (or loss) function; the decision-theoretic optimum maximizes
    the expected utility.
    &#34;&#34;&#34;
    self._log_like = 0.
    for name in self.predictor_names:
        self._log_like += getattr(self, name).log_like()
    self._log_prior = self.log_prior()
    return self._log_like + self._log_prior</code></pre>
</details>
</dd>
<dt id="inference.pie.BayesianInference.set_proposer"><code class="name flex">
<span>def <span class="ident">set_proposer</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Define the proposal distribution for MCMC posterior sampling.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_proposer(self):
    &#34;&#34;&#34;Define the proposal distribution for MCMC posterior sampling.&#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="inference.pie.inference_base.Inference" href="inference_base.html#inference.pie.inference_base.Inference">Inference</a></b></code>:
<ul class="hlist">
<li><code><a title="inference.pie.inference_base.Inference.do_grid" href="inference_base.html#inference.pie.inference_base.Inference.do_grid">do_grid</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.fit" href="inference_base.html#inference.pie.inference_base.Inference.fit">fit</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.get_params" href="inference_base.html#inference.pie.inference_base.Inference.get_params">get_params</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.map_bounds" href="inference_base.html#inference.pie.inference_base.Inference.map_bounds">map_bounds</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.next_step" href="inference_base.html#inference.pie.inference_base.Inference.next_step">next_step</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.optimize" href="inference_base.html#inference.pie.inference_base.Inference.optimize">optimize</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.reset_steps" href="inference_base.html#inference.pie.inference_base.Inference.reset_steps">reset_steps</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.set_params" href="inference_base.html#inference.pie.inference_base.Inference.set_params">set_params</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.show" href="inference_base.html#inference.pie.inference_base.Inference.show">show</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.show_status" href="inference_base.html#inference.pie.inference_base.Inference.show_status">show_status</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.step_nums" href="inference_base.html#inference.pie.inference_base.Inference.step_nums">step_nums</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.step_shape" href="inference_base.html#inference.pie.inference_base.Inference.step_shape">step_shape</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.unmap_bounds" href="inference_base.html#inference.pie.inference_base.Inference.unmap_bounds">unmap_bounds</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="inference.pie.ChisqrInference"><code class="flex name class">
<span>class <span class="ident">ChisqrInference</span></span>
</code></dt>
<dd>
<div class="desc"><p>Base class for inferences made by minimizing a chi**2 statistic
(a weighted sum of squared residuals).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ChisqrInference(Inference):
    &#34;&#34;&#34;Base class for inferences made by minimizing a chi**2 statistic
    (a weighted sum of squared residuals).&#34;&#34;&#34;

    # Smaller values of chi**2 are preferred!
    extremize = minimize

    # Set default minimization method and tolerance
    min_method = &#39;powell&#39;
    min_tol = 1.e-6

    def score(self):
        &#34;&#34;&#34;The function to *minimize* in a fit; i.e., parameters with
        *smaller* values of this function are preferred to those with
        larger values.

        For chi**2 fitting, this is simply chi**2.&#34;&#34;&#34;
        chi2 = 0.
        for name in self.predictor_names:
            chi2 += getattr(self, name).chisqr()
        return chi2</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="inference.pie.inference_base.Inference" href="inference_base.html#inference.pie.inference_base.Inference">Inference</a></li>
<li><a title="inference.pie.autoname.HasAutoNamed" href="autoname.html#inference.pie.autoname.HasAutoNamed">HasAutoNamed</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="inference.pie.ChisqrInference.extremize"><code class="name">var <span class="ident">extremize</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="inference.pie.ChisqrInference.min_method"><code class="name">var <span class="ident">min_method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="inference.pie.ChisqrInference.min_tol"><code class="name">var <span class="ident">min_tol</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="inference.pie.ChisqrInference.score"><code class="name flex">
<span>def <span class="ident">score</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>The function to <em>minimize</em> in a fit; i.e., parameters with
<em>smaller</em> values of this function are preferred to those with
larger values.</p>
<p>For chi<strong>2 fitting, this is simply chi</strong>2.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def score(self):
    &#34;&#34;&#34;The function to *minimize* in a fit; i.e., parameters with
    *smaller* values of this function are preferred to those with
    larger values.

    For chi**2 fitting, this is simply chi**2.&#34;&#34;&#34;
    chi2 = 0.
    for name in self.predictor_names:
        chi2 += getattr(self, name).chisqr()
    return chi2</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="inference.pie.inference_base.Inference" href="inference_base.html#inference.pie.inference_base.Inference">Inference</a></b></code>:
<ul class="hlist">
<li><code><a title="inference.pie.inference_base.Inference.do_grid" href="inference_base.html#inference.pie.inference_base.Inference.do_grid">do_grid</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.fit" href="inference_base.html#inference.pie.inference_base.Inference.fit">fit</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.get_params" href="inference_base.html#inference.pie.inference_base.Inference.get_params">get_params</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.map_bounds" href="inference_base.html#inference.pie.inference_base.Inference.map_bounds">map_bounds</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.next_step" href="inference_base.html#inference.pie.inference_base.Inference.next_step">next_step</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.optimize" href="inference_base.html#inference.pie.inference_base.Inference.optimize">optimize</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.reset_steps" href="inference_base.html#inference.pie.inference_base.Inference.reset_steps">reset_steps</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.set_params" href="inference_base.html#inference.pie.inference_base.Inference.set_params">set_params</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.show" href="inference_base.html#inference.pie.inference_base.Inference.show">show</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.show_status" href="inference_base.html#inference.pie.inference_base.Inference.show_status">show_status</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.step_nums" href="inference_base.html#inference.pie.inference_base.Inference.step_nums">step_nums</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.step_shape" href="inference_base.html#inference.pie.inference_base.Inference.step_shape">step_shape</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.unmap_bounds" href="inference_base.html#inference.pie.inference_base.Inference.unmap_bounds">unmap_bounds</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="inference.pie.DataError"><code class="flex name class">
<span>class <span class="ident">DataError</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Common base class for all non-exit exceptions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DataError(Exception):
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="inference.pie.InferenceError"><code class="flex name class">
<span>class <span class="ident">InferenceError</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Common base class for all non-exit exceptions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class InferenceError(Exception):
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="inference.pie.MaxLikeInference"><code class="flex name class">
<span>class <span class="ident">MaxLikeInference</span></span>
</code></dt>
<dd>
<div class="desc"><p>Base class for maximum likelihood inferences.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MaxLikeInference(Inference):
    &#34;&#34;&#34;
    Base class for maximum likelihood inferences.
    &#34;&#34;&#34;

    # Larger values of likelihood are preferred!
    extremize = maximize

    # Set default minimization method and tolerance
    min_method = &#39;powell&#39;
    min_tol = 1.e-6

    def score(self):
        &#34;&#34;&#34;
        The function to optimize in a fit---here the log likelihood.
        &#34;&#34;&#34;
        self._log_like = 0.
        for name in self.predictor_names:
            self._log_like += getattr(self, name).log_like()
        return self._log_like</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="inference.pie.inference_base.Inference" href="inference_base.html#inference.pie.inference_base.Inference">Inference</a></li>
<li><a title="inference.pie.autoname.HasAutoNamed" href="autoname.html#inference.pie.autoname.HasAutoNamed">HasAutoNamed</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="inference.pie.MaxLikeInference.extremize"><code class="name">var <span class="ident">extremize</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="inference.pie.MaxLikeInference.min_method"><code class="name">var <span class="ident">min_method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="inference.pie.MaxLikeInference.min_tol"><code class="name">var <span class="ident">min_tol</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="inference.pie.MaxLikeInference.score"><code class="name flex">
<span>def <span class="ident">score</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>The function to optimize in a fit&mdash;here the log likelihood.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def score(self):
    &#34;&#34;&#34;
    The function to optimize in a fit---here the log likelihood.
    &#34;&#34;&#34;
    self._log_like = 0.
    for name in self.predictor_names:
        self._log_like += getattr(self, name).log_like()
    return self._log_like</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="inference.pie.inference_base.Inference" href="inference_base.html#inference.pie.inference_base.Inference">Inference</a></b></code>:
<ul class="hlist">
<li><code><a title="inference.pie.inference_base.Inference.do_grid" href="inference_base.html#inference.pie.inference_base.Inference.do_grid">do_grid</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.fit" href="inference_base.html#inference.pie.inference_base.Inference.fit">fit</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.get_params" href="inference_base.html#inference.pie.inference_base.Inference.get_params">get_params</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.map_bounds" href="inference_base.html#inference.pie.inference_base.Inference.map_bounds">map_bounds</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.next_step" href="inference_base.html#inference.pie.inference_base.Inference.next_step">next_step</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.optimize" href="inference_base.html#inference.pie.inference_base.Inference.optimize">optimize</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.reset_steps" href="inference_base.html#inference.pie.inference_base.Inference.reset_steps">reset_steps</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.set_params" href="inference_base.html#inference.pie.inference_base.Inference.set_params">set_params</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.show" href="inference_base.html#inference.pie.inference_base.Inference.show">show</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.show_status" href="inference_base.html#inference.pie.inference_base.Inference.show_status">show_status</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.step_nums" href="inference_base.html#inference.pie.inference_base.Inference.step_nums">step_nums</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.step_shape" href="inference_base.html#inference.pie.inference_base.Inference.step_shape">step_shape</a></code></li>
<li><code><a title="inference.pie.inference_base.Inference.unmap_bounds" href="inference_base.html#inference.pie.inference_base.Inference.unmap_bounds">unmap_bounds</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="inference.pie.PredictorSet"><code class="flex name class">
<span>class <span class="ident">PredictorSet</span></span>
</code></dt>
<dd>
<div class="desc"><p>A base class for classes containing one or more predictors
together defining the sample space and sampling distributions
for an inference.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PredictorSet(HasAutoNamed):
    &#34;&#34;&#34;A base class for classes containing one or more predictors
    together defining the sample space and sampling distributions
    for an inference.&#34;&#34;&#34;

    def clone(self):
        &#34;&#34;&#34;Return a PredictorSet *class* that copies the current data.
        This will be useful only if data has been simulated; this
        will allow analysis of a particular simulated data set with
        various models/methods.&#34;&#34;&#34;
        raise NotImplementedError</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="inference.pie.autoname.HasAutoNamed" href="autoname.html#inference.pie.autoname.HasAutoNamed">HasAutoNamed</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="inference.pie.PredictorSet.clone"><code class="name flex">
<span>def <span class="ident">clone</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a PredictorSet <em>class</em> that copies the current data.
This will be useful only if data has been simulated; this
will allow analysis of a particular simulated data set with
various models/methods.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clone(self):
    &#34;&#34;&#34;Return a PredictorSet *class* that copies the current data.
    This will be useful only if data has been simulated; this
    will allow analysis of a particular simulated data set with
    various models/methods.&#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="inference.pie.RealParam"><code class="flex name class">
<span>class <span class="ident">RealParam</span></span>
<span>(</span><span>value, doc='Undocumented real parameter.')</span>
</code></dt>
<dd>
<div class="desc"><p>A real-valued (i.e., float-valued) parameter.</p>
<p>Accessing an instance of this class returns an object that behaves like
a float in calculations, but carries additional state and methods making
it behave like a model parameter (e.g., ranges, parameter nature, etc.).</p>
<p>RealParam is implemented as an autonamed descriptor (by subclassing Param).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RealParam(Param):
    &#34;&#34;&#34;
    A real-valued (i.e., float-valued) parameter.

    Accessing an instance of this class returns an object that behaves like
    a float in calculations, but carries additional state and methods making
    it behave like a model parameter (e.g., ranges, parameter nature, etc.).

    RealParam is implemented as an autonamed descriptor (by subclassing Param).
    &#34;&#34;&#34;

    handler_class = RealParamHandler

    def __init__(self, value, doc=&#39;Undocumented real parameter.&#39;):
        # Note: these are stored in the *class* (not instance) dict (i.e., the
        # RealParam instance is a class variable, not an instance variable).
        # They will be copied to the instance via the handler.
        self.default = value
        self.doc = doc</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="inference.pie.param.Param" href="param.html#inference.pie.param.Param">Param</a></li>
<li><a title="inference.pie.autoname.AutoNamed" href="autoname.html#inference.pie.autoname.AutoNamed">AutoNamed</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="inference.pie.RealParam.handler_class"><code class="name">var <span class="ident">handler_class</span></code></dt>
<dd>
<div class="desc"><p>Handler that takes care of access to RealParam attributes other
than the basic float value.</p></div>
</dd>
</dl>
</dd>
<dt id="inference.pie.SampledGaussian"><code class="flex name class">
<span>class <span class="ident">SampledGaussian</span></span>
<span>(</span><span>*args, **kwds)</span>
</code></dt>
<dd>
<div class="desc"><p>Predictor for data consisting of a function sampled at fixed, known points
and measured with noise with Gaussian uncertainties of known std dev'n.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SampledGaussian(Predictor):
    &#34;&#34;&#34;
    Predictor for data consisting of a function sampled at fixed, known points
    and measured with noise with Gaussian uncertainties of known std dev&#39;n.
    &#34;&#34;&#34;
    
    # This is implemented as a descriptor; its instances are meant to appear as
    # *class* variables in Inference or PredictorSet (sub)classes.  This means
    # that attributes of &#39;self&#39; are stored in those classes&#39; dictionaries, not
    # in the dict of an instance of such classes.  Thus we use self only for
    # storing copies of the &#39;original&#39; data associated with the predictor;
    # this becomes &#39;global&#39; (i.e., cross-instance) data accessible to every
    # instance of a given Predictor. Instance-specific state (modified data,
    # predictions, etc.) is maintained in the instance dict via a handler.
    #
    # To emphasize that the original data is accessible to multiple
    # instances and thus should be considered &#39;immutable,&#39; such data are
    # stored in attributes with leading underscores.
    
    handler_class = SampledGaussianHandler
    
    def __init__(self, *args, **kwds):
        print(&#39;args:&#39;, args)
        try:
            self.doc = kwds[&#39;doc&#39;]
        except KeyError:
            self.doc = None
        if args:
            self.set_data(*args)
        else:
        # *** Implement this; need locns, sigmas; or require explicit values=None.
        # This will be for pure simulation studies.
        # !!! This string confuses Eclipse&#39;s PyDev syntax colorizer for later strings.
            raise NotImplementedError(&#39;&#34;Template&#34; predictors not yet implemented!&#39;)
            
    def set_data(self, *args):
        &#34;&#34;&#34;
        Set the data from arrays of locns, values &amp; sigmas or an array of triples.
        
        If three arguments are passed, they are interpreted as arrays of
        locations, values, and sigmas respectively.
        
        If a single array is passed, it is interpreted as an array of 3-tuples,
        with each tuple of the form (locn, value, sigma) for a datum.
        &#34;&#34;&#34;
        if len(args) == 3:
            self._locns, self._vals, self._sigmas = args
            if len(self._locns) != len(self._vals) or \
            len(self._vals) != len(self._sigmas):
                raise DataError(&#39;Mismatch in lengths of arguments!&#39;)
        elif len(args) == 1:
            all = args[0]
            try:
                rows, cols = all.shape
                self.locns = all[:,0]
                self.vals = all[:,1]
                self.sigmas = all[:,2]
            except AttributeError:
            # If *all* is not an array, treat it as a list.
            # Only the list format can handle &gt;1-d locns using
            # a single set_data argument.
            # *** Not really - the dimension is shape[1]-2.
                self._locns, self._vals, self._sigmas = [], [], []
                for row in all:
                    self._locns.append(row[0])
                    self._vals.append(row[1])
                    self._sigmas.append(row[2])
                self._locns = array(self.locns)
                self._vals = array(self.vals)
                self._sigmas = array(self.sigmas)
            except:
                raise DataError(&#39;Bad data array format!&#39;)
                # *** Should ndata, dimen be _ndata...?  Or eliminate _...?
                # Lean toward latter, since handler will catch accesses (test this!).
        self.ndata = len(self._vals)
        if len(self._locns.shape) == 1:
            self.dimen = 1
        elif len(self._locns.shape) == 2:
            self.dimen = self.locns.shape[1]
        else:
            raise DataError(&#39;Locations should be scalars or 1-d arrays!&#39;)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="inference.pie.predictor.Predictor" href="predictor.html#inference.pie.predictor.Predictor">Predictor</a></li>
<li><a title="inference.pie.autoname.AutoNamed" href="autoname.html#inference.pie.autoname.AutoNamed">AutoNamed</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="inference.pie.SampledGaussian.handler_class"><code class="name">var <span class="ident">handler_class</span></code></dt>
<dd>
<div class="desc"><p>The handler that handles the method lookups for instances of a Predictor.</p>
<p>An instance of this class is returned when the Predictor is accessed.
Thus methods and attributes of this class appear as if they were
methods and attributes of the Predictor.
This implements instance-specific
state and behavior, even though the Predictor is a class variable.</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="inference.pie.SampledGaussian.set_data"><code class="name flex">
<span>def <span class="ident">set_data</span></span>(<span>self, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the data from arrays of locns, values &amp; sigmas or an array of triples.</p>
<p>If three arguments are passed, they are interpreted as arrays of
locations, values, and sigmas respectively.</p>
<p>If a single array is passed, it is interpreted as an array of 3-tuples,
with each tuple of the form (locn, value, sigma) for a datum.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_data(self, *args):
    &#34;&#34;&#34;
    Set the data from arrays of locns, values &amp; sigmas or an array of triples.
    
    If three arguments are passed, they are interpreted as arrays of
    locations, values, and sigmas respectively.
    
    If a single array is passed, it is interpreted as an array of 3-tuples,
    with each tuple of the form (locn, value, sigma) for a datum.
    &#34;&#34;&#34;
    if len(args) == 3:
        self._locns, self._vals, self._sigmas = args
        if len(self._locns) != len(self._vals) or \
        len(self._vals) != len(self._sigmas):
            raise DataError(&#39;Mismatch in lengths of arguments!&#39;)
    elif len(args) == 1:
        all = args[0]
        try:
            rows, cols = all.shape
            self.locns = all[:,0]
            self.vals = all[:,1]
            self.sigmas = all[:,2]
        except AttributeError:
        # If *all* is not an array, treat it as a list.
        # Only the list format can handle &gt;1-d locns using
        # a single set_data argument.
        # *** Not really - the dimension is shape[1]-2.
            self._locns, self._vals, self._sigmas = [], [], []
            for row in all:
                self._locns.append(row[0])
                self._vals.append(row[1])
                self._sigmas.append(row[2])
            self._locns = array(self.locns)
            self._vals = array(self.vals)
            self._sigmas = array(self.sigmas)
        except:
            raise DataError(&#39;Bad data array format!&#39;)
            # *** Should ndata, dimen be _ndata...?  Or eliminate _...?
            # Lean toward latter, since handler will catch accesses (test this!).
    self.ndata = len(self._vals)
    if len(self._locns.shape) == 1:
        self.dimen = 1
    elif len(self._locns.shape) == 2:
        self.dimen = self.locns.shape[1]
    else:
        raise DataError(&#39;Locations should be scalars or 1-d arrays!&#39;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="inference.pie.SignalModel"><code class="flex name class">
<span>class <span class="ident">SignalModel</span></span>
</code></dt>
<dd>
<div class="desc"><p>Base class for parameterized signal models.
This must be mixed in with a
subclass of the Inference base class that actually oversees most of the
parameter bookkeeping.</p>
<p>Users must override <em>signal</em> and optionally <em>signals</em>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SignalModel(HasAutoNamed):
    &#34;&#34;&#34;
    Base class for parameterized signal models.  This must be mixed in with a
    subclass of the Inference base class that actually oversees most of the
    parameter bookkeeping.
    
    Users must override *signal* and optionally *signals*.
    &#34;&#34;&#34;
    # ??? Should we require signal if signals is defined?

    # *** Note that none of the param state-monitoring methods can
    # be defined to use *predictor* parameters (they won&#39;t exist in the
    # user&#39;s SignalModel subclass).  Is this a
    # significant limitation?  Predictor parameters should
    # not affect calculation of the signal, so I don&#39;t think
    # it&#39;s a significant limitation.

    def signal(self, *args):
        &#34;&#34;&#34;
        Override this method to return the value(s) defined by the model.
        
        To calculate them, access the parameter values as attributes of self
        (e.g., &#34;self.theta&#34;).  The arguments to this method should be quantities
        *other than* the model parameters needed for evaluating the model, 
        e.g., the abscissa at which a fitted function is being evaluated.
        &#34;&#34;&#34;
        raise NotImplementedError

    def signals(self, argvec):
        &#34;&#34;&#34;
        Override this method to return the value(s) defined by the model for
        a vector containing many sets of arguments for the model.  Use vector
        operations, ufuncs, or custom extensions to accelerate the calculation.
        &#34;&#34;&#34;
        raise NotImplementedError

    def on_param_change(self, param):
        &#34;&#34;&#34;
        Note when the value of a parameter is changed.
        
        Override this if work must be done whenever a param value changes; the
        most common scenario where this may be the case is when the allowed 
        ranges of the parameters are coupled, in which case a check for
        parameter validity should be implemented via this method.  Another use
        case is when derived parameter values (that are not Param instances)
        must be updated.
        
        More common model setup chores, such as initializing interpolators,
        should be implemented via on_use, since such setup work is usually not
        necessary until actually evaluating model output, which may not happen
        until after several parameters are changed.
        
        Do *not* assign any parameters in this method; this will cause
        runaway recursive calling of `on_param_change`.
        &#34;&#34;&#34;
        pass

    def on_use(self):
        &#34;&#34;&#34;
        Called when the parameters of the model actually get *used* for
        calculating model signal values.  Override this, e.g., to initialize a
        table lookup or interpolator, or to do other &#34;setup&#34; work that need not
        change when the model value is evaluated for different arguments.
        &#34;&#34;&#34;
        pass

    def _on_param_value_change(self, param):
        &#34;&#34;&#34;
        A &#34;buffer&#34; between internal calls and the user&#39;s on_param_change
        method, insulating the user from maintaining on_use_done.
        &#34;&#34;&#34;
        self.on_use_done = False
        self.on_param_change(param)

    def _on_use(self):
        &#34;&#34;&#34;
        A &#34;buffer&#34; between internal calls and the user&#39;s on_use method,
        insulating the user from maintaining on_use_done.
        &#34;&#34;&#34;
        self.on_use()
        self.on_use_done = True</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="inference.pie.autoname.HasAutoNamed" href="autoname.html#inference.pie.autoname.HasAutoNamed">HasAutoNamed</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="inference.pie.SignalModel.on_param_change"><code class="name flex">
<span>def <span class="ident">on_param_change</span></span>(<span>self, param)</span>
</code></dt>
<dd>
<div class="desc"><p>Note when the value of a parameter is changed.</p>
<p>Override this if work must be done whenever a param value changes; the
most common scenario where this may be the case is when the allowed
ranges of the parameters are coupled, in which case a check for
parameter validity should be implemented via this method.
Another use
case is when derived parameter values (that are not Param instances)
must be updated.</p>
<p>More common model setup chores, such as initializing interpolators,
should be implemented via on_use, since such setup work is usually not
necessary until actually evaluating model output, which may not happen
until after several parameters are changed.</p>
<p>Do <em>not</em> assign any parameters in this method; this will cause
runaway recursive calling of <code>on_param_change</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_param_change(self, param):
    &#34;&#34;&#34;
    Note when the value of a parameter is changed.
    
    Override this if work must be done whenever a param value changes; the
    most common scenario where this may be the case is when the allowed 
    ranges of the parameters are coupled, in which case a check for
    parameter validity should be implemented via this method.  Another use
    case is when derived parameter values (that are not Param instances)
    must be updated.
    
    More common model setup chores, such as initializing interpolators,
    should be implemented via on_use, since such setup work is usually not
    necessary until actually evaluating model output, which may not happen
    until after several parameters are changed.
    
    Do *not* assign any parameters in this method; this will cause
    runaway recursive calling of `on_param_change`.
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="inference.pie.SignalModel.on_use"><code class="name flex">
<span>def <span class="ident">on_use</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Called when the parameters of the model actually get <em>used</em> for
calculating model signal values.
Override this, e.g., to initialize a
table lookup or interpolator, or to do other "setup" work that need not
change when the model value is evaluated for different arguments.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_use(self):
    &#34;&#34;&#34;
    Called when the parameters of the model actually get *used* for
    calculating model signal values.  Override this, e.g., to initialize a
    table lookup or interpolator, or to do other &#34;setup&#34; work that need not
    change when the model value is evaluated for different arguments.
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="inference.pie.SignalModel.signal"><code class="name flex">
<span>def <span class="ident">signal</span></span>(<span>self, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Override this method to return the value(s) defined by the model.</p>
<p>To calculate them, access the parameter values as attributes of self
(e.g., "self.theta").
The arguments to this method should be quantities
<em>other than</em> the model parameters needed for evaluating the model,
e.g., the abscissa at which a fitted function is being evaluated.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def signal(self, *args):
    &#34;&#34;&#34;
    Override this method to return the value(s) defined by the model.
    
    To calculate them, access the parameter values as attributes of self
    (e.g., &#34;self.theta&#34;).  The arguments to this method should be quantities
    *other than* the model parameters needed for evaluating the model, 
    e.g., the abscissa at which a fitted function is being evaluated.
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="inference.pie.SignalModel.signals"><code class="name flex">
<span>def <span class="ident">signals</span></span>(<span>self, argvec)</span>
</code></dt>
<dd>
<div class="desc"><p>Override this method to return the value(s) defined by the model for
a vector containing many sets of arguments for the model.
Use vector
operations, ufuncs, or custom extensions to accelerate the calculation.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def signals(self, argvec):
    &#34;&#34;&#34;
    Override this method to return the value(s) defined by the model for
    a vector containing many sets of arguments for the model.  Use vector
    operations, ufuncs, or custom extensions to accelerate the calculation.
    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="inference" href="../index.html">inference</a></code></li>
</ul>
</li>
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="inference.pie.autoname" href="autoname.html">inference.pie.autoname</a></code></li>
<li><code><a title="inference.pie.bayes" href="bayes.html">inference.pie.bayes</a></code></li>
<li><code><a title="inference.pie.chisqr" href="chisqr.html">inference.pie.chisqr</a></code></li>
<li><code><a title="inference.pie.containers" href="containers.html">inference.pie.containers</a></code></li>
<li><code><a title="inference.pie.gaussian" href="gaussian.html">inference.pie.gaussian</a></code></li>
<li><code><a title="inference.pie.inference_base" href="inference_base.html">inference.pie.inference_base</a></code></li>
<li><code><a title="inference.pie.logger" href="logger.html">inference.pie.logger</a></code></li>
<li><code><a title="inference.pie.maxlike" href="maxlike.html">inference.pie.maxlike</a></code></li>
<li><code><a title="inference.pie.param" href="param.html">inference.pie.param</a></code></li>
<li><code><a title="inference.pie.predictor" href="predictor.html">inference.pie.predictor</a></code></li>
<li><code><a title="inference.pie.realparam" href="realparam.html">inference.pie.realparam</a></code></li>
<li><code><a title="inference.pie.setup" href="setup.html">inference.pie.setup</a></code></li>
<li><code><a title="inference.pie.signalmodel" href="signalmodel.html">inference.pie.signalmodel</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="inference.pie.BayesianInference" href="#inference.pie.BayesianInference">BayesianInference</a></code></h4>
<ul class="two-column">
<li><code><a title="inference.pie.BayesianInference.MCMC_method" href="#inference.pie.BayesianInference.MCMC_method">MCMC_method</a></code></li>
<li><code><a title="inference.pie.BayesianInference.MH_step" href="#inference.pie.BayesianInference.MH_step">MH_step</a></code></li>
<li><code><a title="inference.pie.BayesianInference.MH_steps" href="#inference.pie.BayesianInference.MH_steps">MH_steps</a></code></li>
<li><code><a title="inference.pie.BayesianInference.extremize" href="#inference.pie.BayesianInference.extremize">extremize</a></code></li>
<li><code><a title="inference.pie.BayesianInference.laplace" href="#inference.pie.BayesianInference.laplace">laplace</a></code></li>
<li><code><a title="inference.pie.BayesianInference.logp" href="#inference.pie.BayesianInference.logp">logp</a></code></li>
<li><code><a title="inference.pie.BayesianInference.marg" href="#inference.pie.BayesianInference.marg">marg</a></code></li>
<li><code><a title="inference.pie.BayesianInference.min_method" href="#inference.pie.BayesianInference.min_method">min_method</a></code></li>
<li><code><a title="inference.pie.BayesianInference.min_tol" href="#inference.pie.BayesianInference.min_tol">min_tol</a></code></li>
<li><code><a title="inference.pie.BayesianInference.obs_info" href="#inference.pie.BayesianInference.obs_info">obs_info</a></code></li>
<li><code><a title="inference.pie.BayesianInference.proposal" href="#inference.pie.BayesianInference.proposal">proposal</a></code></li>
<li><code><a title="inference.pie.BayesianInference.score" href="#inference.pie.BayesianInference.score">score</a></code></li>
<li><code><a title="inference.pie.BayesianInference.set_proposer" href="#inference.pie.BayesianInference.set_proposer">set_proposer</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="inference.pie.ChisqrInference" href="#inference.pie.ChisqrInference">ChisqrInference</a></code></h4>
<ul class="">
<li><code><a title="inference.pie.ChisqrInference.extremize" href="#inference.pie.ChisqrInference.extremize">extremize</a></code></li>
<li><code><a title="inference.pie.ChisqrInference.min_method" href="#inference.pie.ChisqrInference.min_method">min_method</a></code></li>
<li><code><a title="inference.pie.ChisqrInference.min_tol" href="#inference.pie.ChisqrInference.min_tol">min_tol</a></code></li>
<li><code><a title="inference.pie.ChisqrInference.score" href="#inference.pie.ChisqrInference.score">score</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="inference.pie.DataError" href="#inference.pie.DataError">DataError</a></code></h4>
</li>
<li>
<h4><code><a title="inference.pie.InferenceError" href="#inference.pie.InferenceError">InferenceError</a></code></h4>
</li>
<li>
<h4><code><a title="inference.pie.MaxLikeInference" href="#inference.pie.MaxLikeInference">MaxLikeInference</a></code></h4>
<ul class="">
<li><code><a title="inference.pie.MaxLikeInference.extremize" href="#inference.pie.MaxLikeInference.extremize">extremize</a></code></li>
<li><code><a title="inference.pie.MaxLikeInference.min_method" href="#inference.pie.MaxLikeInference.min_method">min_method</a></code></li>
<li><code><a title="inference.pie.MaxLikeInference.min_tol" href="#inference.pie.MaxLikeInference.min_tol">min_tol</a></code></li>
<li><code><a title="inference.pie.MaxLikeInference.score" href="#inference.pie.MaxLikeInference.score">score</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="inference.pie.PredictorSet" href="#inference.pie.PredictorSet">PredictorSet</a></code></h4>
<ul class="">
<li><code><a title="inference.pie.PredictorSet.clone" href="#inference.pie.PredictorSet.clone">clone</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="inference.pie.RealParam" href="#inference.pie.RealParam">RealParam</a></code></h4>
<ul class="">
<li><code><a title="inference.pie.RealParam.handler_class" href="#inference.pie.RealParam.handler_class">handler_class</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="inference.pie.SampledGaussian" href="#inference.pie.SampledGaussian">SampledGaussian</a></code></h4>
<ul class="">
<li><code><a title="inference.pie.SampledGaussian.handler_class" href="#inference.pie.SampledGaussian.handler_class">handler_class</a></code></li>
<li><code><a title="inference.pie.SampledGaussian.set_data" href="#inference.pie.SampledGaussian.set_data">set_data</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="inference.pie.SignalModel" href="#inference.pie.SignalModel">SignalModel</a></code></h4>
<ul class="">
<li><code><a title="inference.pie.SignalModel.on_param_change" href="#inference.pie.SignalModel.on_param_change">on_param_change</a></code></li>
<li><code><a title="inference.pie.SignalModel.on_use" href="#inference.pie.SignalModel.on_use">on_use</a></code></li>
<li><code><a title="inference.pie.SignalModel.signal" href="#inference.pie.SignalModel.signal">signal</a></code></li>
<li><code><a title="inference.pie.SignalModel.signals" href="#inference.pie.SignalModel.signals">signals</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>