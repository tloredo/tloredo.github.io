<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>inference.mc API documentation</title>
<meta name="description" content="montecarlo:
Modules implementing Monte Carlo sampling methods" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>inference.mc</code></h1>
</header>
<section id="section-intro">
<p>montecarlo:
Modules implementing Monte Carlo sampling methods</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
montecarlo:  Modules implementing Monte Carlo sampling methods
&#34;&#34;&#34;

from . import population
from .population import Population
from . import pwlinear
from .pwlinear import PWLinear

__all__ = [&#39;population&#39;, &#39;Population&#39;, &#39;PWLinear&#39;]</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="inference.mc.population" href="population.html">inference.mc.population</a></code></dt>
<dd>
<div class="desc"><p>Classes and functions for describing and sampling discrete populations.</p></div>
</dd>
<dt><code class="name"><a title="inference.mc.pwlinear" href="pwlinear.html">inference.mc.pwlinear</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="inference.mc.setup" href="setup.html">inference.mc.setup</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="inference.mc.PWLinear"><code class="flex name class">
<span>class <span class="ident">PWLinear</span></span>
<span>(</span><span>lo=None, hi=None, vals=None, absc=None, step='lin', logvals=False, cut=1e-09)</span>
</code></dt>
<dd>
<div class="desc"><p>Use an array of (non-negative) function values on a grid to define a
piecewise-linear pdf.
Methods evaluate the pdf and draw samples from it.</p>
<p>Define a piecewise linear probability density from an array of
(non-negative) function values.
The algorithm targets use with
very large arrays that might include large regions of negligibly
small values and should remain efficient in that case.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>lo</code></strong>, <strong><code>hi</code></strong> :&ensp;<code>real</code></dt>
<dd>If provided, these define the domain of the pdf, and <code>vals</code> is
assumed to be values on a uniform grid over the domain.
<code>absc</code>
must not be provided if <code>lo</code> and <code>hi</code> are provided.</dd>
<dt><strong><code>absc</code></strong> :&ensp;<code>array_like</code></dt>
<dd>If provided, this array specifies the argument (abscissa) for each
value in <code>vals</code>.
<code>lo</code> and <code>hi</code> must not be provided if <code>absc</code> is
provided.
<code>step</code> is ignored.</dd>
<dt><strong><code>vals</code></strong> :&ensp;<code>array_like</code></dt>
<dd>Non-negative values defining the pdf.
They need not be normalized.</dd>
<dt><strong><code>cut</code></strong> :&ensp;<code>real</code></dt>
<dd>Specifies a cutoff; density values a factor of <code>cut</code> below the
maximum density will be treated as zero.
Must be nonzero if
<code>logvals</code> is True.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PWLinear(object):
    &#34;&#34;&#34;
    Use an array of (non-negative) function values on a grid to define a 
    piecewise-linear pdf.  Methods evaluate the pdf and draw samples from it.
    &#34;&#34;&#34;

    # We&#39;ll ignore periods with marginal density below exp(smallexp)
    # times the max.  exp(-21) = 7.6e-10 (~ 1/billion).
    smallexp = -21.

    def __init__(self, lo=None, hi=None, vals=None, absc=None,
                 step=&#39;lin&#39;, logvals=False, cut=1.e-9):
        &#34;&#34;&#34;
        Define a piecewise linear probability density from an array of 
        (non-negative) function values.  The algorithm targets use with
        very large arrays that might include large regions of negligibly
        small values and should remain efficient in that case.
        
        Parameters
        ----------
        lo, hi : real
            If provided, these define the domain of the pdf, and `vals` is
            assumed to be values on a uniform grid over the domain.  `absc`
            must not be provided if `lo` and `hi` are provided.
        absc : array_like
            If provided, this array specifies the argument (abscissa) for each 
            value in `vals`.  `lo` and `hi` must not be provided if `absc` is
            provided.  `step` is ignored.
        vals : array_like
            Non-negative values defining the pdf.  They need not be normalized.
        cut : real
            Specifies a cutoff; density values a factor of `cut` below the
            maximum density will be treated as zero.  Must be nonzero if
            `logvals` is True.
        &#34;&#34;&#34;
        # Define the domain and abscissas.
        if not (lo is None) and not (hi is None):
            if step != &#39;lin&#39;:
                raise NotImplementedError(&#39;Only linear step is implemented!&#39;)
            self.lo, self.hi = lo, hi
            self.n = len(vals)
            self.step = &#39;lin&#39;
            self.absc, self.delta = linspace(lo, hi, self.n, retstep=True)
        elif absc is None:
            raise ValueError(&#39;Must specify either lo and hi, or absc!&#39;)
        else:
            self.n = len(vals)
            if len(absc) != self.n:
                raise ValueError(&#39;Length mismatch between absc and vals!&#39;)
            self.lo, self.hi = absc[0], absc[-1]
            self.absc = absc
            self.step = None  # indicates arbitrary step sizes

        # Define and select the non-negligible values, &#39;weight values.&#39;
        if logvals:
            wvals = vals - max(vals)
            selected = (wvals &gt; log(cut)).nonzero()[0]
            negl = (wvals &lt;= log(cut)).nonzero()[0]
            wvals[selected] = exp(wvals[selected])
            wvals[negl] = 0.
        else:
            wvals = vals/max(vals)
            selected = (wvals &gt; cut).nonzero()[0]

        # Break up the selection into contiguous regions.
        # First get lists of indices to nonzero values in each region.
        regions = []
        region = [ selected[0] ]
        for n in selected[1:]:
            if n==region[-1]+1:
                region.append(n)
            else:
                regions.append(region)
                region = [n]
        regions.append(region)

        # Now adjust interior boundaries to include a bounding zero value.
        # Just keep track of the range spanned by each region.
        # Start with first region, which may start at index 0.
        lo, hi = regions[0][0], regions[0][-1]
        if lo &gt; 0 and wvals[lo] &gt; 0.:  # must do 2nd test in case cut=0.
            lo -= 1
        if hi &lt; self.n-1 and wvals[hi] &gt; 0.:
            hi += 1
        ranges = [ (lo, hi) ]
        # Run over remaining regions.
        for region in regions[1:]:
            lo, hi = region[0], region[-1]
            if wvals[lo] &gt; 0.:
                lo -= 1
            if hi &lt; self.n-1 and wvals[hi] &gt; 0.:
                hi += 1
            ranges.append((lo,hi))

        # Now, by region, count intervals and calculate weights for nonzero
        # intervals.
        self.n_intvls = 0
        self.regions = []
        nz_wts = []  # wts for regions with nonzero support
        nz_intvls = []
        nz_pdf = []
        for lo,hi in ranges:
            self.n_intvls += hi-lo
            self.regions.append((lo, hi, self.absc[lo], self.absc[hi]))
            intvls = zeros((hi-lo, 2), float)
            # Keep track of the interval boundaries.
            intvls[:,0] = self.absc[lo:hi]  # lower boundaries
            intvls[:,1] = self.absc[lo+1:hi+1]  # upper boundaries
            nz_intvls.append(intvls)
            # Weights are just trapezoid areas.
            wts = 0.5*(wvals[lo:hi]+wvals[lo+1:hi+1]) * (intvls[:,1]-intvls[:,0])
            nz_wts.append(wts)
            pdf = zeros((hi-lo, 2), float)
            pdf[:,0] = wvals[lo:hi]
            pdf[:,1] = wvals[lo+1:hi+1]
            nz_pdf.append(pdf)
        self.nz_wts = concatenate(nz_wts)
        self.norm = self.nz_wts.sum()
        self.nz_wts = self.nz_wts / self.norm
        self.pdf_vals = wvals / self.norm
        self.nz_intvls = concatenate(nz_intvls)
        self.nz_pdf = concatenate(nz_pdf)
        self.nz_centers = 0.5*self.nz_intvls.sum(1)
        self.nz_widths = self.nz_intvls[:,1] - self.nz_intvls[:,0]
        self.popn = Population(weights=self.nz_wts)

    def sample(self, n=None):
        &#34;&#34;&#34;
        Return pseudo-random samples from the piecewise linear pdf.
        
        With no argument, a single sample is returned; otherwise the
        requested number is returned as a 1-D array.
        &#34;&#34;&#34;
        if n is None:
            index = self.popn.sample(1)[0]
            lo, hi = self.nz_intvls[index]
            plo, phi = self.nz_pdf[index]
            if plo==phi:  # handle flat intervals
                # print &#39;flat:&#39;, index, lo, hi, lo + (hi-lo)*rand()
                return lo + (hi-lo)*rand()
            else:
                r = (hi-lo)/(phi-plo)
                return lo - r*plo + r*sqrt(plo**2 + (phi**2 - plo**2)*rand())
                # return self.nz_centers[index]
        else:
            indices = self.popn.sample(n)
            lo, hi = self.nz_intvls[indices,0], self.nz_intvls[indices,1]
            plo, phi = self.nz_pdf[indices,0], self.nz_pdf[indices,1]
            flat = (phi==plo).nonzero()[0]  # id the flat intervals
            r = (hi-lo)/(phi-plo)  # will be NaN for flat intervals
            u = rand(n)
#             if len(flat) != 0:
#                 print plo**2 + (phi**2 - plo**2)*u
#                 print r
#                 print indices
#                 print phi-plo
            vals = lo - r*plo + r*sqrt(plo**2 + (phi**2 - plo**2)*u)
            if len(flat) != 0:
                vals[flat] = lo[flat] + (hi[flat]-lo[flat])*u[flat]
            return vals
            # return self.nz_centers[indices]

    def pdf(self, x):
        &#34;&#34;&#34;
        Calculate the probability density for sampling at x (scalar or vector).
        
        This returns the density from the piecewise linear interpolation,
        including adjustment for the cutoff, i.e., for places with density
        below the cutoff, this returns 0.  Thus this is an accurate pdf
        for the samples returned by `sample`.
        &#34;&#34;&#34;
        if iterable(x):
            dens = empty(len(x), float)
            for i, xval in enumerate(x):
                dens[i] = self._pdf(xval)
            return dens
        else:
            return self._pdf(x)

    def _pdf(self, x):
        &#34;&#34;&#34;
        Calculate the probability density for sampling at a single point, x.

        This returns the density from the piecewise linear interpolation,
        including adjustment for the cutoff, i.e., for places with density
        below the cutoff, this returns 0.  Thus this is an accurate pdf
        for the samples returned by `sample`.
        &#34;&#34;&#34;
        # Find the region containing x.
        inside = None
        for region in self.regions:
            if x &gt;= region[2] and x &lt;= region[3]:
                inside = region
                break
        if inside is None:  # x not in any region
            return 0.
        # Handle arbitrary step size case.
        if self.step is None:
            # Do bisection within the region to find the containing interval.
            raise NotImplementedError
        # Handle even step size case.
        elif self.step == &#39;lin&#39;:
            i = region[0] + int((x - region[2])/self.delta)
            return self.pdf_vals[i] + \
                (self.pdf_vals[i+1]-self.pdf_vals[i]) * \
                (x - self.absc[i])/(self.absc[i+1] - self.absc[i])
        else:  # log step case
            raise NotImplementedError(&#39;log step size not yet implemented!&#39;)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="inference.mc.PWLinear.smallexp"><code class="name">var <span class="ident">smallexp</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="inference.mc.PWLinear.pdf"><code class="name flex">
<span>def <span class="ident">pdf</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the probability density for sampling at x (scalar or vector).</p>
<p>This returns the density from the piecewise linear interpolation,
including adjustment for the cutoff, i.e., for places with density
below the cutoff, this returns 0.
Thus this is an accurate pdf
for the samples returned by <code>sample</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pdf(self, x):
    &#34;&#34;&#34;
    Calculate the probability density for sampling at x (scalar or vector).
    
    This returns the density from the piecewise linear interpolation,
    including adjustment for the cutoff, i.e., for places with density
    below the cutoff, this returns 0.  Thus this is an accurate pdf
    for the samples returned by `sample`.
    &#34;&#34;&#34;
    if iterable(x):
        dens = empty(len(x), float)
        for i, xval in enumerate(x):
            dens[i] = self._pdf(xval)
        return dens
    else:
        return self._pdf(x)</code></pre>
</details>
</dd>
<dt id="inference.mc.PWLinear.sample"><code class="name flex">
<span>def <span class="ident">sample</span></span>(<span>self, n=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return pseudo-random samples from the piecewise linear pdf.</p>
<p>With no argument, a single sample is returned; otherwise the
requested number is returned as a 1-D array.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">    def sample(self, n=None):
        &#34;&#34;&#34;
        Return pseudo-random samples from the piecewise linear pdf.
        
        With no argument, a single sample is returned; otherwise the
        requested number is returned as a 1-D array.
        &#34;&#34;&#34;
        if n is None:
            index = self.popn.sample(1)[0]
            lo, hi = self.nz_intvls[index]
            plo, phi = self.nz_pdf[index]
            if plo==phi:  # handle flat intervals
                # print &#39;flat:&#39;, index, lo, hi, lo + (hi-lo)*rand()
                return lo + (hi-lo)*rand()
            else:
                r = (hi-lo)/(phi-plo)
                return lo - r*plo + r*sqrt(plo**2 + (phi**2 - plo**2)*rand())
                # return self.nz_centers[index]
        else:
            indices = self.popn.sample(n)
            lo, hi = self.nz_intvls[indices,0], self.nz_intvls[indices,1]
            plo, phi = self.nz_pdf[indices,0], self.nz_pdf[indices,1]
            flat = (phi==plo).nonzero()[0]  # id the flat intervals
            r = (hi-lo)/(phi-plo)  # will be NaN for flat intervals
            u = rand(n)
#             if len(flat) != 0:
#                 print plo**2 + (phi**2 - plo**2)*u
#                 print r
#                 print indices
#                 print phi-plo
            vals = lo - r*plo + r*sqrt(plo**2 + (phi**2 - plo**2)*u)
            if len(flat) != 0:
                vals[flat] = lo[flat] + (hi[flat]-lo[flat])*u[flat]
            return vals
            # return self.nz_centers[indices]</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="inference.mc.Population"><code class="flex name class">
<span>class <span class="ident">Population</span></span>
<span>(</span><span>items=None, weights=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Population(object):

    def __init__(self, items=None, weights=None):
        if weights is None:  # The equal probability case
            self.equiprob = True
            try:  # items is a sequence
                self.npopn = len(items)
                self.items = items
            except TypeError:  # items is an int
                self.npopn = int(items)
                self.items = list(range(self.npopn))
        elif items is None:  # Use indices as items
            self.equiprob = False
            self.npopn = len(weights)
            self.items = list(range(self.npopn))
            self.weights = array(weights, float)
        else:  # Use a list of items *and* weights
            self.equiprob = False
            self.npopn = len(weights)
            if len(items) != self.npopn:
                raise ValueError(&#39;Lengths of items &amp; weights must match!&#39;)
            self.items = items
            self.weights = array(weights, float)

        self.did_init = False
        self.did_Sampford_init = False
        self.did_Sampford_tables = False

    def sample(self, nsamp):
        &#34;&#34;&#34;
        Return a set of nsamp samples from the population, sampled with
        replacement.
        &#34;&#34;&#34;
        # *** Implement equiprob case.
        if self.equiprob:
            raise NotImplementedError(&#39;Awaiting code...&#39;)
        if not self.did_init:
            self.sampler = _ppssampler(self.weights)
            self.did_init = True
        # Track the RNG state within the sampler, to update NumPy&#39;s RNG state.
        # Internally we only use the MT state; any extra state for cached
        # normal or other samples can just be copied.
        rng_state = random.get_state()
        mt_state, extra_state = rng_state[:3], rng_state[3:]
        set_rng_state(*mt_state)  # *** modify to handle full rng state
        indices = self.sampler.sample(nsamp)
        new_state = list(get_rng_state())
        new_state.extend(extra_state)
        random.set_state(new_state)
        return [self.items[i] for i in indices]

    def max_subset(self):
        &#34;&#34;&#34;
        Return the maximum sample size for PPS sampling without replacement.

        The limiting size arises because PPS sampling without replacement 
        requires nsamp*(max normalized weight) &lt;= 1.  If this is violated
        for the desired sample size, you may consider trimming the large
        weight members from the population and including them in every
        sample (of course, they will all have inclusion probability of
        unity, regardless of size).
        &#34;&#34;&#34;
        if self.did_Sampford_init:
            return int(1./self.max_wt)
        else:
            return int(sum(self.weights)/self.weights.max())

    def subset_pps(self, nsamp):
        &#34;&#34;&#34;
        Return a sample of nsamp distinct items from the population, sampled 
        without replacement with probability proportional to size (PPS)
        according to Sampford&#39;s sampling scheme.
        &#34;&#34;&#34;
        # Copy the whole population if nsamp = npopn.
        if nsamp == self.npopn:
            return [item for item in self.items]
        set_rng_state(*random.get_state())
        if self.equiprob:
            pool = arange(self.npopn)
            indices = equalprob(nsamp, pool)
        else:
            # This part of setup has to be done before any sampling.
            if not self.did_init:
                print(&#39;Initing ppssampler...&#39;)
                self.sampler = _ppssampler(self.weights)
                self.did_init = True
            # This part has to be done before any sampling w/o replacement.
            if not self.did_Sampford_init:
                print(&#39;Initing wts...&#39;)
                self.sort_indices, self.sort_wts, self.tot_wt = \
                    self.sampler.prepwts(self.weights)
                self.max_wt = self.sort_wts[0]/self.tot_wt  # Max wt, normed
                self.nsamp = 0
                self.did_Sampford_init = True
                self.did_Sampford_tables = False
            # This part has to be done when sample size changes.
            if self.nsamp != nsamp:
                print(&#39;Initing ratios...&#39;)
                if nsamp &gt; self.npopn:
                    raise ValueError(&#39;nsamp larger than population size!&#39;)
                if nsamp*self.max_wt &gt; 1:
                    raise ValueError(&#39;Sample size too large for PPS sampling!&#39;)
                self.sampler.prepratios(nsamp, self.sort_wts, self.tot_wt)
                self.did_Sampford_tables = False
                self.nsamp = nsamp
            self.ntry, sindices = self.sampler.samplenr()
            indices = [self.sort_indices[i] for i in sindices]
        result = [self.items[i] for i in indices]
        random.set_state(get_rng_state())
        return result

    def subset_pps5(self, nsamp):
        &#34;&#34;&#34;
        Return a sample of nsamp distinct items from the population, sampled 
        without replacement with probability proportional to size (PPS)
        according to Sampford&#39;s sampling scheme.

        5-table lookup samplers are used within Sampford&#39;s algorithm to
        accelerate the sampling for large populations.
        &#34;&#34;&#34;
        # Copy the whole population if nsamp = npopn.
        if nsamp == self.npopn:
            return [item for item in self.items]
        set_rng_state(*random.get_state())
        if self.equiprob:
            pool = arange(self.npopn)
            indices = equalprob(nsamp, pool)
        else:
            # This part of setup has to be done before any sampling.
            if not self.did_init:
                print(&#39;Initing ppssampler...&#39;)
                self.sampler = _ppssampler(self.weights)
                self.did_init = True
            # This part has to be done before any sampling w/o replacement.
            if not self.did_Sampford_init:
                print(&#39;Initing wts...&#39;)
                self.sort_indices, self.sort_wts, self.tot_wt = \
                    self.sampler.prepwts(self.weights)
                self.max_wt = self.sort_wts[0]/self.tot_wt  # Max wt, normed
                self.nsamp = 0
                self.did_Sampford_init = True
            # This part has to be done when sample size changes.
            if self.nsamp != nsamp:
                print(&#39;Initing ratios...&#39;)
                if nsamp &gt; self.npopn:
                    raise ValueError(&#39;nsamp larger than population size!&#39;)
                if nsamp*self.max_wt &gt; 1:
                    raise ValueError(&#39;Sample size too large for PPS sampling!&#39;)
                self.sampler.prepratios(nsamp, self.sort_wts, self.tot_wt)
                self.sampler.prepratiotables()
                self.did_Sampford_tables = True
                self.nsamp = nsamp
            # This may happen if subset_pps is called before subset_pps5.
            if not self.did_Sampford_tables:
                print(&#39;Initing ratio tables...&#39;)
                self.sampler.prepratiotables()
                self.did_Sampford_tables = True
            self.ntry, indices = self.sampler.samplenr5()
            # Note the 5-table version returns unsorted indices.
            # indices = [self.sort_indices[i] for i in sindices]
        result = [self.items[i] for i in indices]
        random.set_state(get_rng_state())
        return result</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="inference.mc.population.Population1D" href="population.html#inference.mc.population.Population1D">Population1D</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="inference.mc.Population.max_subset"><code class="name flex">
<span>def <span class="ident">max_subset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the maximum sample size for PPS sampling without replacement.</p>
<p>The limiting size arises because PPS sampling without replacement
requires nsamp*(max normalized weight) &lt;= 1.
If this is violated
for the desired sample size, you may consider trimming the large
weight members from the population and including them in every
sample (of course, they will all have inclusion probability of
unity, regardless of size).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def max_subset(self):
    &#34;&#34;&#34;
    Return the maximum sample size for PPS sampling without replacement.

    The limiting size arises because PPS sampling without replacement 
    requires nsamp*(max normalized weight) &lt;= 1.  If this is violated
    for the desired sample size, you may consider trimming the large
    weight members from the population and including them in every
    sample (of course, they will all have inclusion probability of
    unity, regardless of size).
    &#34;&#34;&#34;
    if self.did_Sampford_init:
        return int(1./self.max_wt)
    else:
        return int(sum(self.weights)/self.weights.max())</code></pre>
</details>
</dd>
<dt id="inference.mc.Population.sample"><code class="name flex">
<span>def <span class="ident">sample</span></span>(<span>self, nsamp)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a set of nsamp samples from the population, sampled with
replacement.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample(self, nsamp):
    &#34;&#34;&#34;
    Return a set of nsamp samples from the population, sampled with
    replacement.
    &#34;&#34;&#34;
    # *** Implement equiprob case.
    if self.equiprob:
        raise NotImplementedError(&#39;Awaiting code...&#39;)
    if not self.did_init:
        self.sampler = _ppssampler(self.weights)
        self.did_init = True
    # Track the RNG state within the sampler, to update NumPy&#39;s RNG state.
    # Internally we only use the MT state; any extra state for cached
    # normal or other samples can just be copied.
    rng_state = random.get_state()
    mt_state, extra_state = rng_state[:3], rng_state[3:]
    set_rng_state(*mt_state)  # *** modify to handle full rng state
    indices = self.sampler.sample(nsamp)
    new_state = list(get_rng_state())
    new_state.extend(extra_state)
    random.set_state(new_state)
    return [self.items[i] for i in indices]</code></pre>
</details>
</dd>
<dt id="inference.mc.Population.subset_pps"><code class="name flex">
<span>def <span class="ident">subset_pps</span></span>(<span>self, nsamp)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a sample of nsamp distinct items from the population, sampled
without replacement with probability proportional to size (PPS)
according to Sampford's sampling scheme.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def subset_pps(self, nsamp):
    &#34;&#34;&#34;
    Return a sample of nsamp distinct items from the population, sampled 
    without replacement with probability proportional to size (PPS)
    according to Sampford&#39;s sampling scheme.
    &#34;&#34;&#34;
    # Copy the whole population if nsamp = npopn.
    if nsamp == self.npopn:
        return [item for item in self.items]
    set_rng_state(*random.get_state())
    if self.equiprob:
        pool = arange(self.npopn)
        indices = equalprob(nsamp, pool)
    else:
        # This part of setup has to be done before any sampling.
        if not self.did_init:
            print(&#39;Initing ppssampler...&#39;)
            self.sampler = _ppssampler(self.weights)
            self.did_init = True
        # This part has to be done before any sampling w/o replacement.
        if not self.did_Sampford_init:
            print(&#39;Initing wts...&#39;)
            self.sort_indices, self.sort_wts, self.tot_wt = \
                self.sampler.prepwts(self.weights)
            self.max_wt = self.sort_wts[0]/self.tot_wt  # Max wt, normed
            self.nsamp = 0
            self.did_Sampford_init = True
            self.did_Sampford_tables = False
        # This part has to be done when sample size changes.
        if self.nsamp != nsamp:
            print(&#39;Initing ratios...&#39;)
            if nsamp &gt; self.npopn:
                raise ValueError(&#39;nsamp larger than population size!&#39;)
            if nsamp*self.max_wt &gt; 1:
                raise ValueError(&#39;Sample size too large for PPS sampling!&#39;)
            self.sampler.prepratios(nsamp, self.sort_wts, self.tot_wt)
            self.did_Sampford_tables = False
            self.nsamp = nsamp
        self.ntry, sindices = self.sampler.samplenr()
        indices = [self.sort_indices[i] for i in sindices]
    result = [self.items[i] for i in indices]
    random.set_state(get_rng_state())
    return result</code></pre>
</details>
</dd>
<dt id="inference.mc.Population.subset_pps5"><code class="name flex">
<span>def <span class="ident">subset_pps5</span></span>(<span>self, nsamp)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a sample of nsamp distinct items from the population, sampled
without replacement with probability proportional to size (PPS)
according to Sampford's sampling scheme.</p>
<p>5-table lookup samplers are used within Sampford's algorithm to
accelerate the sampling for large populations.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def subset_pps5(self, nsamp):
    &#34;&#34;&#34;
    Return a sample of nsamp distinct items from the population, sampled 
    without replacement with probability proportional to size (PPS)
    according to Sampford&#39;s sampling scheme.

    5-table lookup samplers are used within Sampford&#39;s algorithm to
    accelerate the sampling for large populations.
    &#34;&#34;&#34;
    # Copy the whole population if nsamp = npopn.
    if nsamp == self.npopn:
        return [item for item in self.items]
    set_rng_state(*random.get_state())
    if self.equiprob:
        pool = arange(self.npopn)
        indices = equalprob(nsamp, pool)
    else:
        # This part of setup has to be done before any sampling.
        if not self.did_init:
            print(&#39;Initing ppssampler...&#39;)
            self.sampler = _ppssampler(self.weights)
            self.did_init = True
        # This part has to be done before any sampling w/o replacement.
        if not self.did_Sampford_init:
            print(&#39;Initing wts...&#39;)
            self.sort_indices, self.sort_wts, self.tot_wt = \
                self.sampler.prepwts(self.weights)
            self.max_wt = self.sort_wts[0]/self.tot_wt  # Max wt, normed
            self.nsamp = 0
            self.did_Sampford_init = True
        # This part has to be done when sample size changes.
        if self.nsamp != nsamp:
            print(&#39;Initing ratios...&#39;)
            if nsamp &gt; self.npopn:
                raise ValueError(&#39;nsamp larger than population size!&#39;)
            if nsamp*self.max_wt &gt; 1:
                raise ValueError(&#39;Sample size too large for PPS sampling!&#39;)
            self.sampler.prepratios(nsamp, self.sort_wts, self.tot_wt)
            self.sampler.prepratiotables()
            self.did_Sampford_tables = True
            self.nsamp = nsamp
        # This may happen if subset_pps is called before subset_pps5.
        if not self.did_Sampford_tables:
            print(&#39;Initing ratio tables...&#39;)
            self.sampler.prepratiotables()
            self.did_Sampford_tables = True
        self.ntry, indices = self.sampler.samplenr5()
        # Note the 5-table version returns unsorted indices.
        # indices = [self.sort_indices[i] for i in sindices]
    result = [self.items[i] for i in indices]
    random.set_state(get_rng_state())
    return result</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="inference" href="../index.html">inference</a></code></li>
</ul>
</li>
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="inference.mc.population" href="population.html">inference.mc.population</a></code></li>
<li><code><a title="inference.mc.pwlinear" href="pwlinear.html">inference.mc.pwlinear</a></code></li>
<li><code><a title="inference.mc.setup" href="setup.html">inference.mc.setup</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="inference.mc.PWLinear" href="#inference.mc.PWLinear">PWLinear</a></code></h4>
<ul class="">
<li><code><a title="inference.mc.PWLinear.pdf" href="#inference.mc.PWLinear.pdf">pdf</a></code></li>
<li><code><a title="inference.mc.PWLinear.sample" href="#inference.mc.PWLinear.sample">sample</a></code></li>
<li><code><a title="inference.mc.PWLinear.smallexp" href="#inference.mc.PWLinear.smallexp">smallexp</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="inference.mc.Population" href="#inference.mc.Population">Population</a></code></h4>
<ul class="">
<li><code><a title="inference.mc.Population.max_subset" href="#inference.mc.Population.max_subset">max_subset</a></code></li>
<li><code><a title="inference.mc.Population.sample" href="#inference.mc.Population.sample">sample</a></code></li>
<li><code><a title="inference.mc.Population.subset_pps" href="#inference.mc.Population.subset_pps">subset_pps</a></code></li>
<li><code><a title="inference.mc.Population.subset_pps5" href="#inference.mc.Population.subset_pps5">subset_pps5</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>