<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>inference.mc.population API documentation</title>
<meta name="description" content="Classes and functions for describing and sampling discrete populations." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>inference.mc.population</code></h1>
</header>
<section id="section-intro">
<p>Classes and functions for describing and sampling discrete populations.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Classes and functions for describing and sampling discrete populations.
&#34;&#34;&#34;

# TODO:  Distinguish sizes from weights (normalized).

__author__ = &#34;Tom Loredo&#34;

from numpy import array, random
# TODO:  Use placeholders until updating _ppsampler
# from _ppssampler import _ppssampler, equalprob
# from _ppssampler import set_rng_state, get_rng_state
from inference.utils.pl import pl
# try:
#     import pylab as pl
# except ImportError:
#     pl = None

__all__ = [&#39;Population&#39;, &#39;Population1D&#39;]

# Placeholders:
_ppssampler = object()
equalprob = object()
set_rng_state = object()
get_rng_state = object()


class Population(object):

    def __init__(self, items=None, weights=None):
        if weights is None:  # The equal probability case
            self.equiprob = True
            try:  # items is a sequence
                self.npopn = len(items)
                self.items = items
            except TypeError:  # items is an int
                self.npopn = int(items)
                self.items = list(range(self.npopn))
        elif items is None:  # Use indices as items
            self.equiprob = False
            self.npopn = len(weights)
            self.items = list(range(self.npopn))
            self.weights = array(weights, float)
        else:  # Use a list of items *and* weights
            self.equiprob = False
            self.npopn = len(weights)
            if len(items) != self.npopn:
                raise ValueError(&#39;Lengths of items &amp; weights must match!&#39;)
            self.items = items
            self.weights = array(weights, float)

        self.did_init = False
        self.did_Sampford_init = False
        self.did_Sampford_tables = False

    def sample(self, nsamp):
        &#34;&#34;&#34;
        Return a set of nsamp samples from the population, sampled with
        replacement.
        &#34;&#34;&#34;
        # *** Implement equiprob case.
        if self.equiprob:
            raise NotImplementedError(&#39;Awaiting code...&#39;)
        if not self.did_init:
            self.sampler = _ppssampler(self.weights)
            self.did_init = True
        # Track the RNG state within the sampler, to update NumPy&#39;s RNG state.
        # Internally we only use the MT state; any extra state for cached
        # normal or other samples can just be copied.
        rng_state = random.get_state()
        mt_state, extra_state = rng_state[:3], rng_state[3:]
        set_rng_state(*mt_state)  # *** modify to handle full rng state
        indices = self.sampler.sample(nsamp)
        new_state = list(get_rng_state())
        new_state.extend(extra_state)
        random.set_state(new_state)
        return [self.items[i] for i in indices]

    def max_subset(self):
        &#34;&#34;&#34;
        Return the maximum sample size for PPS sampling without replacement.

        The limiting size arises because PPS sampling without replacement 
        requires nsamp*(max normalized weight) &lt;= 1.  If this is violated
        for the desired sample size, you may consider trimming the large
        weight members from the population and including them in every
        sample (of course, they will all have inclusion probability of
        unity, regardless of size).
        &#34;&#34;&#34;
        if self.did_Sampford_init:
            return int(1./self.max_wt)
        else:
            return int(sum(self.weights)/self.weights.max())

    def subset_pps(self, nsamp):
        &#34;&#34;&#34;
        Return a sample of nsamp distinct items from the population, sampled 
        without replacement with probability proportional to size (PPS)
        according to Sampford&#39;s sampling scheme.
        &#34;&#34;&#34;
        # Copy the whole population if nsamp = npopn.
        if nsamp == self.npopn:
            return [item for item in self.items]
        set_rng_state(*random.get_state())
        if self.equiprob:
            pool = arange(self.npopn)
            indices = equalprob(nsamp, pool)
        else:
            # This part of setup has to be done before any sampling.
            if not self.did_init:
                print(&#39;Initing ppssampler...&#39;)
                self.sampler = _ppssampler(self.weights)
                self.did_init = True
            # This part has to be done before any sampling w/o replacement.
            if not self.did_Sampford_init:
                print(&#39;Initing wts...&#39;)
                self.sort_indices, self.sort_wts, self.tot_wt = \
                    self.sampler.prepwts(self.weights)
                self.max_wt = self.sort_wts[0]/self.tot_wt  # Max wt, normed
                self.nsamp = 0
                self.did_Sampford_init = True
                self.did_Sampford_tables = False
            # This part has to be done when sample size changes.
            if self.nsamp != nsamp:
                print(&#39;Initing ratios...&#39;)
                if nsamp &gt; self.npopn:
                    raise ValueError(&#39;nsamp larger than population size!&#39;)
                if nsamp*self.max_wt &gt; 1:
                    raise ValueError(&#39;Sample size too large for PPS sampling!&#39;)
                self.sampler.prepratios(nsamp, self.sort_wts, self.tot_wt)
                self.did_Sampford_tables = False
                self.nsamp = nsamp
            self.ntry, sindices = self.sampler.samplenr()
            indices = [self.sort_indices[i] for i in sindices]
        result = [self.items[i] for i in indices]
        random.set_state(get_rng_state())
        return result

    def subset_pps5(self, nsamp):
        &#34;&#34;&#34;
        Return a sample of nsamp distinct items from the population, sampled 
        without replacement with probability proportional to size (PPS)
        according to Sampford&#39;s sampling scheme.

        5-table lookup samplers are used within Sampford&#39;s algorithm to
        accelerate the sampling for large populations.
        &#34;&#34;&#34;
        # Copy the whole population if nsamp = npopn.
        if nsamp == self.npopn:
            return [item for item in self.items]
        set_rng_state(*random.get_state())
        if self.equiprob:
            pool = arange(self.npopn)
            indices = equalprob(nsamp, pool)
        else:
            # This part of setup has to be done before any sampling.
            if not self.did_init:
                print(&#39;Initing ppssampler...&#39;)
                self.sampler = _ppssampler(self.weights)
                self.did_init = True
            # This part has to be done before any sampling w/o replacement.
            if not self.did_Sampford_init:
                print(&#39;Initing wts...&#39;)
                self.sort_indices, self.sort_wts, self.tot_wt = \
                    self.sampler.prepwts(self.weights)
                self.max_wt = self.sort_wts[0]/self.tot_wt  # Max wt, normed
                self.nsamp = 0
                self.did_Sampford_init = True
            # This part has to be done when sample size changes.
            if self.nsamp != nsamp:
                print(&#39;Initing ratios...&#39;)
                if nsamp &gt; self.npopn:
                    raise ValueError(&#39;nsamp larger than population size!&#39;)
                if nsamp*self.max_wt &gt; 1:
                    raise ValueError(&#39;Sample size too large for PPS sampling!&#39;)
                self.sampler.prepratios(nsamp, self.sort_wts, self.tot_wt)
                self.sampler.prepratiotables()
                self.did_Sampford_tables = True
                self.nsamp = nsamp
            # This may happen if subset_pps is called before subset_pps5.
            if not self.did_Sampford_tables:
                print(&#39;Initing ratio tables...&#39;)
                self.sampler.prepratiotables()
                self.did_Sampford_tables = True
            self.ntry, indices = self.sampler.samplenr5()
            # Note the 5-table version returns unsorted indices.
            # indices = [self.sort_indices[i] for i in sindices]
        result = [self.items[i] for i in indices]
        random.set_state(get_rng_state())
        return result


class Population1D(Population):
    &#34;&#34;&#34;
    A Population object specialized for populations indexed by a
    single (1-D) real-valued quantity that gives the &#34;size&#34; of
    each member.
    &#34;&#34;&#34;

    def __init__(self, vals, weights, err=None):
        indices = array(vals).argsort()
        self.vals = vals[indices].copy()
        self.weights = array(weights)[indices].copy()
        if err == None:
            self.err = None
        else:
            self.err = array(err)[indices].copy()
        Population.__init__(self, self.vals, self.weights)
        self.cdf = self.weights.cumsum()
        self.hazard = self.cdf[::-1].copy()

    def haz_pts(self, start=None, end=None):
        &#34;&#34;&#34;
        Return arrays of points specifying the hazard dist&#39;n over the range
        [start, end].  The range must fully span the range of
        detected values.  Also return arrays of points specifying
        error bars, if defined on creation.
        &#34;&#34;&#34;
        if start is None:
            start = self.vals[0]
        if end is None:
            end = self.vals[-1]
        if start &gt; self.vals[0] or end &lt; self.vals[-1]:
            raise ValueError(&#39;Range must span the range of sampled values!&#39;)
        # Start the descending CDF.
        absc, ord = [start], [1.]
        # Add pairs of points for each uncensored value, defining jumps.
        for x, p in zip(self.vals, self.hazard):
            absc.extend([x, x])
            ord.extend([ord[-1], p])
        # The last step is zero.
        absc.append(end)
        ord.append(0.)
        if self.err == None:
            return array(absc), array(ord)
        else:
            # For error bars, just copy the stored errors in the middle of
            # the CDF bins.
            eabsc = []
            for i in range(len(self.vals)-1):
                eabsc.append(.5*(self.vals[i]+self.vals[i+1]))
            eabsc.append(.5*(self.vals[-1]+end))
            return array(absc), array(ord), array(eabsc), self.hazard.copy(), \
                self.err.copy()

    def plot(self, start=None, end=None):
        &#34;&#34;&#34;
        Plot the hazard over the range [start,end], which must span
        the range of uncensored values.
        &#34;&#34;&#34;
        if not pl:
            raise RuntimeError(&#39;Cannot plot without pylab!&#39;)
        if start is None:
            start = self.vals[0]
        if end is None:
            end = self.vals[-1]
        if self.err == None:
            a, o = self.haz_pts(start, end)
        else:
            a, o, ea, eo, ee = self.haz_pts(start, end)
        pl.plot(a, o, &#39;b-&#39;, linewidth=2)
        if self.err != None:
            pl.errorbar(ea, eo, ee, fmt=&#39;o&#39;, markersize=0)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="inference.mc.population.Population"><code class="flex name class">
<span>class <span class="ident">Population</span></span>
<span>(</span><span>items=None, weights=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Population(object):

    def __init__(self, items=None, weights=None):
        if weights is None:  # The equal probability case
            self.equiprob = True
            try:  # items is a sequence
                self.npopn = len(items)
                self.items = items
            except TypeError:  # items is an int
                self.npopn = int(items)
                self.items = list(range(self.npopn))
        elif items is None:  # Use indices as items
            self.equiprob = False
            self.npopn = len(weights)
            self.items = list(range(self.npopn))
            self.weights = array(weights, float)
        else:  # Use a list of items *and* weights
            self.equiprob = False
            self.npopn = len(weights)
            if len(items) != self.npopn:
                raise ValueError(&#39;Lengths of items &amp; weights must match!&#39;)
            self.items = items
            self.weights = array(weights, float)

        self.did_init = False
        self.did_Sampford_init = False
        self.did_Sampford_tables = False

    def sample(self, nsamp):
        &#34;&#34;&#34;
        Return a set of nsamp samples from the population, sampled with
        replacement.
        &#34;&#34;&#34;
        # *** Implement equiprob case.
        if self.equiprob:
            raise NotImplementedError(&#39;Awaiting code...&#39;)
        if not self.did_init:
            self.sampler = _ppssampler(self.weights)
            self.did_init = True
        # Track the RNG state within the sampler, to update NumPy&#39;s RNG state.
        # Internally we only use the MT state; any extra state for cached
        # normal or other samples can just be copied.
        rng_state = random.get_state()
        mt_state, extra_state = rng_state[:3], rng_state[3:]
        set_rng_state(*mt_state)  # *** modify to handle full rng state
        indices = self.sampler.sample(nsamp)
        new_state = list(get_rng_state())
        new_state.extend(extra_state)
        random.set_state(new_state)
        return [self.items[i] for i in indices]

    def max_subset(self):
        &#34;&#34;&#34;
        Return the maximum sample size for PPS sampling without replacement.

        The limiting size arises because PPS sampling without replacement 
        requires nsamp*(max normalized weight) &lt;= 1.  If this is violated
        for the desired sample size, you may consider trimming the large
        weight members from the population and including them in every
        sample (of course, they will all have inclusion probability of
        unity, regardless of size).
        &#34;&#34;&#34;
        if self.did_Sampford_init:
            return int(1./self.max_wt)
        else:
            return int(sum(self.weights)/self.weights.max())

    def subset_pps(self, nsamp):
        &#34;&#34;&#34;
        Return a sample of nsamp distinct items from the population, sampled 
        without replacement with probability proportional to size (PPS)
        according to Sampford&#39;s sampling scheme.
        &#34;&#34;&#34;
        # Copy the whole population if nsamp = npopn.
        if nsamp == self.npopn:
            return [item for item in self.items]
        set_rng_state(*random.get_state())
        if self.equiprob:
            pool = arange(self.npopn)
            indices = equalprob(nsamp, pool)
        else:
            # This part of setup has to be done before any sampling.
            if not self.did_init:
                print(&#39;Initing ppssampler...&#39;)
                self.sampler = _ppssampler(self.weights)
                self.did_init = True
            # This part has to be done before any sampling w/o replacement.
            if not self.did_Sampford_init:
                print(&#39;Initing wts...&#39;)
                self.sort_indices, self.sort_wts, self.tot_wt = \
                    self.sampler.prepwts(self.weights)
                self.max_wt = self.sort_wts[0]/self.tot_wt  # Max wt, normed
                self.nsamp = 0
                self.did_Sampford_init = True
                self.did_Sampford_tables = False
            # This part has to be done when sample size changes.
            if self.nsamp != nsamp:
                print(&#39;Initing ratios...&#39;)
                if nsamp &gt; self.npopn:
                    raise ValueError(&#39;nsamp larger than population size!&#39;)
                if nsamp*self.max_wt &gt; 1:
                    raise ValueError(&#39;Sample size too large for PPS sampling!&#39;)
                self.sampler.prepratios(nsamp, self.sort_wts, self.tot_wt)
                self.did_Sampford_tables = False
                self.nsamp = nsamp
            self.ntry, sindices = self.sampler.samplenr()
            indices = [self.sort_indices[i] for i in sindices]
        result = [self.items[i] for i in indices]
        random.set_state(get_rng_state())
        return result

    def subset_pps5(self, nsamp):
        &#34;&#34;&#34;
        Return a sample of nsamp distinct items from the population, sampled 
        without replacement with probability proportional to size (PPS)
        according to Sampford&#39;s sampling scheme.

        5-table lookup samplers are used within Sampford&#39;s algorithm to
        accelerate the sampling for large populations.
        &#34;&#34;&#34;
        # Copy the whole population if nsamp = npopn.
        if nsamp == self.npopn:
            return [item for item in self.items]
        set_rng_state(*random.get_state())
        if self.equiprob:
            pool = arange(self.npopn)
            indices = equalprob(nsamp, pool)
        else:
            # This part of setup has to be done before any sampling.
            if not self.did_init:
                print(&#39;Initing ppssampler...&#39;)
                self.sampler = _ppssampler(self.weights)
                self.did_init = True
            # This part has to be done before any sampling w/o replacement.
            if not self.did_Sampford_init:
                print(&#39;Initing wts...&#39;)
                self.sort_indices, self.sort_wts, self.tot_wt = \
                    self.sampler.prepwts(self.weights)
                self.max_wt = self.sort_wts[0]/self.tot_wt  # Max wt, normed
                self.nsamp = 0
                self.did_Sampford_init = True
            # This part has to be done when sample size changes.
            if self.nsamp != nsamp:
                print(&#39;Initing ratios...&#39;)
                if nsamp &gt; self.npopn:
                    raise ValueError(&#39;nsamp larger than population size!&#39;)
                if nsamp*self.max_wt &gt; 1:
                    raise ValueError(&#39;Sample size too large for PPS sampling!&#39;)
                self.sampler.prepratios(nsamp, self.sort_wts, self.tot_wt)
                self.sampler.prepratiotables()
                self.did_Sampford_tables = True
                self.nsamp = nsamp
            # This may happen if subset_pps is called before subset_pps5.
            if not self.did_Sampford_tables:
                print(&#39;Initing ratio tables...&#39;)
                self.sampler.prepratiotables()
                self.did_Sampford_tables = True
            self.ntry, indices = self.sampler.samplenr5()
            # Note the 5-table version returns unsorted indices.
            # indices = [self.sort_indices[i] for i in sindices]
        result = [self.items[i] for i in indices]
        random.set_state(get_rng_state())
        return result</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="inference.mc.population.Population1D" href="#inference.mc.population.Population1D">Population1D</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="inference.mc.population.Population.max_subset"><code class="name flex">
<span>def <span class="ident">max_subset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the maximum sample size for PPS sampling without replacement.</p>
<p>The limiting size arises because PPS sampling without replacement
requires nsamp*(max normalized weight) &lt;= 1.
If this is violated
for the desired sample size, you may consider trimming the large
weight members from the population and including them in every
sample (of course, they will all have inclusion probability of
unity, regardless of size).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def max_subset(self):
    &#34;&#34;&#34;
    Return the maximum sample size for PPS sampling without replacement.

    The limiting size arises because PPS sampling without replacement 
    requires nsamp*(max normalized weight) &lt;= 1.  If this is violated
    for the desired sample size, you may consider trimming the large
    weight members from the population and including them in every
    sample (of course, they will all have inclusion probability of
    unity, regardless of size).
    &#34;&#34;&#34;
    if self.did_Sampford_init:
        return int(1./self.max_wt)
    else:
        return int(sum(self.weights)/self.weights.max())</code></pre>
</details>
</dd>
<dt id="inference.mc.population.Population.sample"><code class="name flex">
<span>def <span class="ident">sample</span></span>(<span>self, nsamp)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a set of nsamp samples from the population, sampled with
replacement.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample(self, nsamp):
    &#34;&#34;&#34;
    Return a set of nsamp samples from the population, sampled with
    replacement.
    &#34;&#34;&#34;
    # *** Implement equiprob case.
    if self.equiprob:
        raise NotImplementedError(&#39;Awaiting code...&#39;)
    if not self.did_init:
        self.sampler = _ppssampler(self.weights)
        self.did_init = True
    # Track the RNG state within the sampler, to update NumPy&#39;s RNG state.
    # Internally we only use the MT state; any extra state for cached
    # normal or other samples can just be copied.
    rng_state = random.get_state()
    mt_state, extra_state = rng_state[:3], rng_state[3:]
    set_rng_state(*mt_state)  # *** modify to handle full rng state
    indices = self.sampler.sample(nsamp)
    new_state = list(get_rng_state())
    new_state.extend(extra_state)
    random.set_state(new_state)
    return [self.items[i] for i in indices]</code></pre>
</details>
</dd>
<dt id="inference.mc.population.Population.subset_pps"><code class="name flex">
<span>def <span class="ident">subset_pps</span></span>(<span>self, nsamp)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a sample of nsamp distinct items from the population, sampled
without replacement with probability proportional to size (PPS)
according to Sampford's sampling scheme.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def subset_pps(self, nsamp):
    &#34;&#34;&#34;
    Return a sample of nsamp distinct items from the population, sampled 
    without replacement with probability proportional to size (PPS)
    according to Sampford&#39;s sampling scheme.
    &#34;&#34;&#34;
    # Copy the whole population if nsamp = npopn.
    if nsamp == self.npopn:
        return [item for item in self.items]
    set_rng_state(*random.get_state())
    if self.equiprob:
        pool = arange(self.npopn)
        indices = equalprob(nsamp, pool)
    else:
        # This part of setup has to be done before any sampling.
        if not self.did_init:
            print(&#39;Initing ppssampler...&#39;)
            self.sampler = _ppssampler(self.weights)
            self.did_init = True
        # This part has to be done before any sampling w/o replacement.
        if not self.did_Sampford_init:
            print(&#39;Initing wts...&#39;)
            self.sort_indices, self.sort_wts, self.tot_wt = \
                self.sampler.prepwts(self.weights)
            self.max_wt = self.sort_wts[0]/self.tot_wt  # Max wt, normed
            self.nsamp = 0
            self.did_Sampford_init = True
            self.did_Sampford_tables = False
        # This part has to be done when sample size changes.
        if self.nsamp != nsamp:
            print(&#39;Initing ratios...&#39;)
            if nsamp &gt; self.npopn:
                raise ValueError(&#39;nsamp larger than population size!&#39;)
            if nsamp*self.max_wt &gt; 1:
                raise ValueError(&#39;Sample size too large for PPS sampling!&#39;)
            self.sampler.prepratios(nsamp, self.sort_wts, self.tot_wt)
            self.did_Sampford_tables = False
            self.nsamp = nsamp
        self.ntry, sindices = self.sampler.samplenr()
        indices = [self.sort_indices[i] for i in sindices]
    result = [self.items[i] for i in indices]
    random.set_state(get_rng_state())
    return result</code></pre>
</details>
</dd>
<dt id="inference.mc.population.Population.subset_pps5"><code class="name flex">
<span>def <span class="ident">subset_pps5</span></span>(<span>self, nsamp)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a sample of nsamp distinct items from the population, sampled
without replacement with probability proportional to size (PPS)
according to Sampford's sampling scheme.</p>
<p>5-table lookup samplers are used within Sampford's algorithm to
accelerate the sampling for large populations.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def subset_pps5(self, nsamp):
    &#34;&#34;&#34;
    Return a sample of nsamp distinct items from the population, sampled 
    without replacement with probability proportional to size (PPS)
    according to Sampford&#39;s sampling scheme.

    5-table lookup samplers are used within Sampford&#39;s algorithm to
    accelerate the sampling for large populations.
    &#34;&#34;&#34;
    # Copy the whole population if nsamp = npopn.
    if nsamp == self.npopn:
        return [item for item in self.items]
    set_rng_state(*random.get_state())
    if self.equiprob:
        pool = arange(self.npopn)
        indices = equalprob(nsamp, pool)
    else:
        # This part of setup has to be done before any sampling.
        if not self.did_init:
            print(&#39;Initing ppssampler...&#39;)
            self.sampler = _ppssampler(self.weights)
            self.did_init = True
        # This part has to be done before any sampling w/o replacement.
        if not self.did_Sampford_init:
            print(&#39;Initing wts...&#39;)
            self.sort_indices, self.sort_wts, self.tot_wt = \
                self.sampler.prepwts(self.weights)
            self.max_wt = self.sort_wts[0]/self.tot_wt  # Max wt, normed
            self.nsamp = 0
            self.did_Sampford_init = True
        # This part has to be done when sample size changes.
        if self.nsamp != nsamp:
            print(&#39;Initing ratios...&#39;)
            if nsamp &gt; self.npopn:
                raise ValueError(&#39;nsamp larger than population size!&#39;)
            if nsamp*self.max_wt &gt; 1:
                raise ValueError(&#39;Sample size too large for PPS sampling!&#39;)
            self.sampler.prepratios(nsamp, self.sort_wts, self.tot_wt)
            self.sampler.prepratiotables()
            self.did_Sampford_tables = True
            self.nsamp = nsamp
        # This may happen if subset_pps is called before subset_pps5.
        if not self.did_Sampford_tables:
            print(&#39;Initing ratio tables...&#39;)
            self.sampler.prepratiotables()
            self.did_Sampford_tables = True
        self.ntry, indices = self.sampler.samplenr5()
        # Note the 5-table version returns unsorted indices.
        # indices = [self.sort_indices[i] for i in sindices]
    result = [self.items[i] for i in indices]
    random.set_state(get_rng_state())
    return result</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="inference.mc.population.Population1D"><code class="flex name class">
<span>class <span class="ident">Population1D</span></span>
<span>(</span><span>vals, weights, err=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A Population object specialized for populations indexed by a
single (1-D) real-valued quantity that gives the "size" of
each member.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Population1D(Population):
    &#34;&#34;&#34;
    A Population object specialized for populations indexed by a
    single (1-D) real-valued quantity that gives the &#34;size&#34; of
    each member.
    &#34;&#34;&#34;

    def __init__(self, vals, weights, err=None):
        indices = array(vals).argsort()
        self.vals = vals[indices].copy()
        self.weights = array(weights)[indices].copy()
        if err == None:
            self.err = None
        else:
            self.err = array(err)[indices].copy()
        Population.__init__(self, self.vals, self.weights)
        self.cdf = self.weights.cumsum()
        self.hazard = self.cdf[::-1].copy()

    def haz_pts(self, start=None, end=None):
        &#34;&#34;&#34;
        Return arrays of points specifying the hazard dist&#39;n over the range
        [start, end].  The range must fully span the range of
        detected values.  Also return arrays of points specifying
        error bars, if defined on creation.
        &#34;&#34;&#34;
        if start is None:
            start = self.vals[0]
        if end is None:
            end = self.vals[-1]
        if start &gt; self.vals[0] or end &lt; self.vals[-1]:
            raise ValueError(&#39;Range must span the range of sampled values!&#39;)
        # Start the descending CDF.
        absc, ord = [start], [1.]
        # Add pairs of points for each uncensored value, defining jumps.
        for x, p in zip(self.vals, self.hazard):
            absc.extend([x, x])
            ord.extend([ord[-1], p])
        # The last step is zero.
        absc.append(end)
        ord.append(0.)
        if self.err == None:
            return array(absc), array(ord)
        else:
            # For error bars, just copy the stored errors in the middle of
            # the CDF bins.
            eabsc = []
            for i in range(len(self.vals)-1):
                eabsc.append(.5*(self.vals[i]+self.vals[i+1]))
            eabsc.append(.5*(self.vals[-1]+end))
            return array(absc), array(ord), array(eabsc), self.hazard.copy(), \
                self.err.copy()

    def plot(self, start=None, end=None):
        &#34;&#34;&#34;
        Plot the hazard over the range [start,end], which must span
        the range of uncensored values.
        &#34;&#34;&#34;
        if not pl:
            raise RuntimeError(&#39;Cannot plot without pylab!&#39;)
        if start is None:
            start = self.vals[0]
        if end is None:
            end = self.vals[-1]
        if self.err == None:
            a, o = self.haz_pts(start, end)
        else:
            a, o, ea, eo, ee = self.haz_pts(start, end)
        pl.plot(a, o, &#39;b-&#39;, linewidth=2)
        if self.err != None:
            pl.errorbar(ea, eo, ee, fmt=&#39;o&#39;, markersize=0)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="inference.mc.population.Population" href="#inference.mc.population.Population">Population</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="inference.mc.population.Population1D.haz_pts"><code class="name flex">
<span>def <span class="ident">haz_pts</span></span>(<span>self, start=None, end=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return arrays of points specifying the hazard dist'n over the range
[start, end].
The range must fully span the range of
detected values.
Also return arrays of points specifying
error bars, if defined on creation.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def haz_pts(self, start=None, end=None):
    &#34;&#34;&#34;
    Return arrays of points specifying the hazard dist&#39;n over the range
    [start, end].  The range must fully span the range of
    detected values.  Also return arrays of points specifying
    error bars, if defined on creation.
    &#34;&#34;&#34;
    if start is None:
        start = self.vals[0]
    if end is None:
        end = self.vals[-1]
    if start &gt; self.vals[0] or end &lt; self.vals[-1]:
        raise ValueError(&#39;Range must span the range of sampled values!&#39;)
    # Start the descending CDF.
    absc, ord = [start], [1.]
    # Add pairs of points for each uncensored value, defining jumps.
    for x, p in zip(self.vals, self.hazard):
        absc.extend([x, x])
        ord.extend([ord[-1], p])
    # The last step is zero.
    absc.append(end)
    ord.append(0.)
    if self.err == None:
        return array(absc), array(ord)
    else:
        # For error bars, just copy the stored errors in the middle of
        # the CDF bins.
        eabsc = []
        for i in range(len(self.vals)-1):
            eabsc.append(.5*(self.vals[i]+self.vals[i+1]))
        eabsc.append(.5*(self.vals[-1]+end))
        return array(absc), array(ord), array(eabsc), self.hazard.copy(), \
            self.err.copy()</code></pre>
</details>
</dd>
<dt id="inference.mc.population.Population1D.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, start=None, end=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the hazard over the range [start,end], which must span
the range of uncensored values.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self, start=None, end=None):
    &#34;&#34;&#34;
    Plot the hazard over the range [start,end], which must span
    the range of uncensored values.
    &#34;&#34;&#34;
    if not pl:
        raise RuntimeError(&#39;Cannot plot without pylab!&#39;)
    if start is None:
        start = self.vals[0]
    if end is None:
        end = self.vals[-1]
    if self.err == None:
        a, o = self.haz_pts(start, end)
    else:
        a, o, ea, eo, ee = self.haz_pts(start, end)
    pl.plot(a, o, &#39;b-&#39;, linewidth=2)
    if self.err != None:
        pl.errorbar(ea, eo, ee, fmt=&#39;o&#39;, markersize=0)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="inference.mc.population.Population" href="#inference.mc.population.Population">Population</a></b></code>:
<ul class="hlist">
<li><code><a title="inference.mc.population.Population.max_subset" href="#inference.mc.population.Population.max_subset">max_subset</a></code></li>
<li><code><a title="inference.mc.population.Population.sample" href="#inference.mc.population.Population.sample">sample</a></code></li>
<li><code><a title="inference.mc.population.Population.subset_pps" href="#inference.mc.population.Population.subset_pps">subset_pps</a></code></li>
<li><code><a title="inference.mc.population.Population.subset_pps5" href="#inference.mc.population.Population.subset_pps5">subset_pps5</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="inference.mc" href="index.html">inference.mc</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="inference.mc.population.Population" href="#inference.mc.population.Population">Population</a></code></h4>
<ul class="">
<li><code><a title="inference.mc.population.Population.max_subset" href="#inference.mc.population.Population.max_subset">max_subset</a></code></li>
<li><code><a title="inference.mc.population.Population.sample" href="#inference.mc.population.Population.sample">sample</a></code></li>
<li><code><a title="inference.mc.population.Population.subset_pps" href="#inference.mc.population.Population.subset_pps">subset_pps</a></code></li>
<li><code><a title="inference.mc.population.Population.subset_pps5" href="#inference.mc.population.Population.subset_pps5">subset_pps5</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="inference.mc.population.Population1D" href="#inference.mc.population.Population1D">Population1D</a></code></h4>
<ul class="">
<li><code><a title="inference.mc.population.Population1D.haz_pts" href="#inference.mc.population.Population1D.haz_pts">haz_pts</a></code></li>
<li><code><a title="inference.mc.population.Population1D.plot" href="#inference.mc.population.Population1D.plot">plot</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>