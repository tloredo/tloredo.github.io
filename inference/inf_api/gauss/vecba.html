<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>inference.gauss.vecba API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>inference.gauss.vecba</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from numpy import ones, zeros, shape, sum, newaxis, sqrt

# TODO: Use placeholder until vba is updated:
# import vba

__all__ = [&#39;BA&#39;, &#39;BAObj&#39;]

# The placeholder:
vba = object()


# A global for alerting user to an untested method.
FIRSTTIME = True


class BA:
    &#34;&#34;&#34;
    Implement the Bretthorst algorithm using a list of functions of the
    nonlinear parameters and an array of abscissas, a data array (abscissas and
    samples, with error sigmas as a 3rd dimension or as a separate, single sigma
    value), and an optional setup function.

    The setup function should take the nonlinear parameters as its arguments,
    and return an object that gets passed to each of the basis functions as
    its final argument.
    &#34;&#34;&#34;

    def __init__(self, basis, data, sigma=None, setup=None):
        &#34;&#34;&#34;Initialize:  Save basic info; calculate standardized data and d**2.&#34;&#34;&#34;

#...    Basic member data.
        self.M = len(basis)
        self.N = len(data)
        self.basis = basis
        self.absc = data[:,0]
        self.smpls = data[:,1]
        if shape(data)[1] != 2 and sigma != None:
            raise ValueError(&#34;Data have sigmas but a sigma was provided!&#34;)
        if sigma != None:
            self.sigs = sigma*ones(self.N, float)
        elif (shape(data)[1] == 3):
            self.sigs = data[:,2]
        else:
            raise ValueError(&#34;Wrong dimensions for data!&#34;)
        self.setup = setup
        self.std_smpls = self.smpls / self.sigs
        self.dsqr = sum(self.std_smpls*self.std_smpls)

#...    We&#39;ll memoize the current params &amp; results to avoid duplicating work.
        self.pars = None
        self.suf = None
        self.Q = None
        self.Jac = None

#...    Space for model values (aka the design matrix).
        self.modvals = zeros((self.M, self.N), float)

#...    We could also deal with constant terms here once for all, to handle
#...    purely linear terms.

    def marg_stats(self, *params):
        &#34;&#34;&#34;
        Return the quadratic form, sufficient statistic, and Jacobian as a
        function of the passed nonlinear parameters.  These statistics allow
        calculation of the marginal density for the nonlinear parameters, and
        other inferences.

        Returns:
            Q - quadratic form (sum of squared residuals)
            suf - sufficient statistic
            Jac - Jacobian determinant

        Let dsqr be the sum of squares of the standardized sample values; then
        Q and suf are related, Q = dsqr - suf.

        The log marginal likelihood for the nonlinear parameters is
        -0.5*Q + log(J).
        &#34;&#34;&#34;
        self.calc_marg_stats(*params)
        return self.Q, self.suf, self.Jac

    def calc_marg_stats(self, *params):
        &#34;&#34;&#34;
        Calculate the marginal density and Jacobian vs. nonlinear parameters
        and memoize the results.
        &#34;&#34;&#34;

        if (params == self.pars):
            return self.Q, self.suf, self.Jac

#...    Evaluate the standardized models on the data, first calling the setup
#...    function for the data if it is present.
        args = list(params)
        args.append(self.absc)
        args = tuple(args)
        if (self.setup != None):
            aux = self.setup(*args)
            args = list(args)
            args.append(aux)
            args = tuple(args)
        for a in range(self.M):
            g = self.basis[a]
            self.modvals[a,:] = g(*args) / self.sigs

#...    Calculate the metric and various derived quantities.  Store them
#...    for possible future use before returning.
        self.metric, self.L, self.Jac, self.proj, self.ampl, self.suf =\
            vba.metricAnalysis(self.modvals, self.std_smpls)
        self.Q = self.dsqr - self.suf
        self.pars = params
        self.Jac = 1. / self.Jac

    def amplitudes(self, *params):
        &#34;&#34;&#34;Calculate the best-fit amplitudes.&#34;&#34;&#34;

#...    If we haven&#39;t already done the metric calculations for these params,
#...    do them.
        if params != () and params != self.pars:
            # print &#34;Calling margStats.&#34;
            self.calc_marg_stats(*params)

#...    Now just return the stored amplitudes..
        return self.ampl

    def covar(self):
        &#34;&#34;&#34;Return the covariance matrix for the best-fit amplitudes.&#34;&#34;&#34;

        global FIRSTTIME
        if FIRSTTIME:
            print(&#39;*** BA method covar is UNTESTED ***&#39;)  # Copied from old version--likely ok.
            FIRSTTIME = False

#...    If we haven&#39;t already done the metric calculations, complain!
        if self.pars == None:
            raise ValueError(&#39;Must calculate marginal first!&#39;)

        return vba.covar(self.L)

    def residuals(self, *params):
        &#34;&#34;&#34;Calculate the standardized residuals.&#34;&#34;&#34;

#...    If we haven&#39;t already done the metric calculations for these params,
#...    do them.
        if (params != () and params != self.pars):
            # print &#34;Calling margStats.&#34;
            self.calc_marg_stats(*params)

#...    Subtract projection from data.
        model = sum(self.ampl[:,newaxis]*self.modvals, 0)
        return self.std_smpls - model


class BAObj:
    &#34;&#34;&#34;
    Implement the Bretthorst algorithm using an object that provides basis
    function and data access through these methods and attributes:

        set_nonlin(*args) - set the nonlinear parameters
        std_smpls[i] - value of the i&#39;th standardized sample
        std_basis[k] - method returning 1-D array of standardized predictions
            from basis function k when called as std_basis[k]()
    &#34;&#34;&#34;

    def __init__(self, obj):
        &#34;&#34;&#34;
        Initialize:  Specify number of basis functions, number of data samples,
        and the object providing basis and data access.
        &#34;&#34;&#34;

#...    Basic member data.
        self.obj = obj
        self.M = len(obj.std_basis)
        self.N = len(obj.std_smpls)
        self.dsqr = sum(obj.std_smpls*obj.std_smpls)

#...    We&#39;ll memoize the current params &amp; results to avoid duplicating work.
        self.pars = None
        self.suf = None
        self.Q = None
        self.Jac = None

#...    Space for model values (aka the design matrix).
        self.modvals = zeros((self.M, self.N), float)

    def marg_stats(self, *params):
        &#34;&#34;&#34;
        Return the quadratic form, sufficient statistic, and Jacobian as a
        function of the passed nonlinear parameters.  These statistics allow
        calculation of the marginal density for the nonlinear parameters, and
        other inferences.

        Returns:
            Q - quadratic form (sum of squared residuals)
            suf - sufficient statistic
            Jac - Jacobian determinant

        Let dsqr be the sum of squares of the standardized sample values; then
        Q and suf are related, Q = dsqr - suf.

        If the prior for the amplitudes is taken to be flat and independent of
        the nonlinear parameters, the log marginal likelihood for the nonlinear
        parameters is
            -0.5*Q + log(Jac)
        However, if a subset of the basis functions becomes (nearly)
        degenerate for some choice of the nonlinear parameters, the likelihood
        becomes constant in one or more directions, and the marginal
        likelihood for that choice of nonlinear parameters will diverge
        because the amplitude integral diverges.  One way to guard against
        this is to make the amplitude prior *depend on the nonlinear
        parameters* proportionally to the volume element in sample space
        spanned by the basis.  Then nonlinear parameter values that cause
        &#34;basis collapse&#34; are penalized (the prior density vanishes for them).
        This corresponds to a prior for the amplitudes proportional to Jac, so
        the log marginal likelihood for the nonlinear parameters is then
            -0.5*Q
        &#34;&#34;&#34;
        self.calc_marg_stats(*params)
        return self.Q, self.suf, self.Jac

    def calc_marg_stats(self, *params):
        &#34;&#34;&#34;
        Calculate the marginal density and Jacobian vs. nonlinear parameters
        and memoize the results.
        &#34;&#34;&#34;

        if (params == self.pars):
            return self.Q, self.suf, self.Jac

#...    Evaluate the standardized models on the data, first calling the setup
#...    function.
        self.obj.set_nonlin(*params)
        for a in range(self.M):
            self.modvals[a,:] = self.obj.std_basis[a]()

#...    Calculate the metric and various derived quantities.  Store them
#...    for possible future use before returning.
        self.metric, self.L, self.Jac, self.proj, self.ampl, self.suf =\
            vba.metricAnalysis(self.modvals, self.obj.std_smpls)
        self.Q = self.dsqr - self.suf
        self.pars = params
        self.Jac = 1. / self.Jac

    def amplitudes(self, *params):
        &#34;&#34;&#34;Calculate the best-fit amplitudes.&#34;&#34;&#34;

#...    If we haven&#39;t already done the metric calculations for these params,
#...    do them.
        if params != () and params != self.pars:
            # print &#34;Calling margStats.&#34;
            self.calc_marg_stats(*params)

#...    Now just return the stored amplitudes.
        return self.ampl

    def covar(self):
        &#34;&#34;&#34;Return the covariance matrix for the best-fit amplitudes.&#34;&#34;&#34;

        global FIRSTTIME
        if FIRSTTIME:
            print(&#39;*** BA method covar is UNTESTED ***&#39;)  # Copied from old version--likely ok.
            FIRSTTIME = False

#...    If we haven&#39;t already done the metric calculations, complain!
        if self.pars == None:
            raise ValueError(&#39;Must calculate marginal first!&#39;)
        return vba.covar(self.L)

    def residuals(self, *params):
        &#34;&#34;&#34;Calculate the standardized residuals.&#34;&#34;&#34;

#...    If we haven&#39;t already done the metric calculations for these params,
#...    do them.
        if (params != () and params != self.pars):
            # print &#34;Calling margStats.&#34;
            self.calc_marg_stats(*params)

#...    Subtract projection from data.
        model = sum(self.ampl[:,newaxis]*self.modvals, 0)
        return self.obj.std_smpls - model</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="inference.gauss.vecba.BA"><code class="flex name class">
<span>class <span class="ident">BA</span></span>
<span>(</span><span>basis, data, sigma=None, setup=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Implement the Bretthorst algorithm using a list of functions of the
nonlinear parameters and an array of abscissas, a data array (abscissas and
samples, with error sigmas as a 3rd dimension or as a separate, single sigma
value), and an optional setup function.</p>
<p>The setup function should take the nonlinear parameters as its arguments,
and return an object that gets passed to each of the basis functions as
its final argument.</p>
<p>Initialize:
Save basic info; calculate standardized data and d**2.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BA:
    &#34;&#34;&#34;
    Implement the Bretthorst algorithm using a list of functions of the
    nonlinear parameters and an array of abscissas, a data array (abscissas and
    samples, with error sigmas as a 3rd dimension or as a separate, single sigma
    value), and an optional setup function.

    The setup function should take the nonlinear parameters as its arguments,
    and return an object that gets passed to each of the basis functions as
    its final argument.
    &#34;&#34;&#34;

    def __init__(self, basis, data, sigma=None, setup=None):
        &#34;&#34;&#34;Initialize:  Save basic info; calculate standardized data and d**2.&#34;&#34;&#34;

#...    Basic member data.
        self.M = len(basis)
        self.N = len(data)
        self.basis = basis
        self.absc = data[:,0]
        self.smpls = data[:,1]
        if shape(data)[1] != 2 and sigma != None:
            raise ValueError(&#34;Data have sigmas but a sigma was provided!&#34;)
        if sigma != None:
            self.sigs = sigma*ones(self.N, float)
        elif (shape(data)[1] == 3):
            self.sigs = data[:,2]
        else:
            raise ValueError(&#34;Wrong dimensions for data!&#34;)
        self.setup = setup
        self.std_smpls = self.smpls / self.sigs
        self.dsqr = sum(self.std_smpls*self.std_smpls)

#...    We&#39;ll memoize the current params &amp; results to avoid duplicating work.
        self.pars = None
        self.suf = None
        self.Q = None
        self.Jac = None

#...    Space for model values (aka the design matrix).
        self.modvals = zeros((self.M, self.N), float)

#...    We could also deal with constant terms here once for all, to handle
#...    purely linear terms.

    def marg_stats(self, *params):
        &#34;&#34;&#34;
        Return the quadratic form, sufficient statistic, and Jacobian as a
        function of the passed nonlinear parameters.  These statistics allow
        calculation of the marginal density for the nonlinear parameters, and
        other inferences.

        Returns:
            Q - quadratic form (sum of squared residuals)
            suf - sufficient statistic
            Jac - Jacobian determinant

        Let dsqr be the sum of squares of the standardized sample values; then
        Q and suf are related, Q = dsqr - suf.

        The log marginal likelihood for the nonlinear parameters is
        -0.5*Q + log(J).
        &#34;&#34;&#34;
        self.calc_marg_stats(*params)
        return self.Q, self.suf, self.Jac

    def calc_marg_stats(self, *params):
        &#34;&#34;&#34;
        Calculate the marginal density and Jacobian vs. nonlinear parameters
        and memoize the results.
        &#34;&#34;&#34;

        if (params == self.pars):
            return self.Q, self.suf, self.Jac

#...    Evaluate the standardized models on the data, first calling the setup
#...    function for the data if it is present.
        args = list(params)
        args.append(self.absc)
        args = tuple(args)
        if (self.setup != None):
            aux = self.setup(*args)
            args = list(args)
            args.append(aux)
            args = tuple(args)
        for a in range(self.M):
            g = self.basis[a]
            self.modvals[a,:] = g(*args) / self.sigs

#...    Calculate the metric and various derived quantities.  Store them
#...    for possible future use before returning.
        self.metric, self.L, self.Jac, self.proj, self.ampl, self.suf =\
            vba.metricAnalysis(self.modvals, self.std_smpls)
        self.Q = self.dsqr - self.suf
        self.pars = params
        self.Jac = 1. / self.Jac

    def amplitudes(self, *params):
        &#34;&#34;&#34;Calculate the best-fit amplitudes.&#34;&#34;&#34;

#...    If we haven&#39;t already done the metric calculations for these params,
#...    do them.
        if params != () and params != self.pars:
            # print &#34;Calling margStats.&#34;
            self.calc_marg_stats(*params)

#...    Now just return the stored amplitudes..
        return self.ampl

    def covar(self):
        &#34;&#34;&#34;Return the covariance matrix for the best-fit amplitudes.&#34;&#34;&#34;

        global FIRSTTIME
        if FIRSTTIME:
            print(&#39;*** BA method covar is UNTESTED ***&#39;)  # Copied from old version--likely ok.
            FIRSTTIME = False

#...    If we haven&#39;t already done the metric calculations, complain!
        if self.pars == None:
            raise ValueError(&#39;Must calculate marginal first!&#39;)

        return vba.covar(self.L)

    def residuals(self, *params):
        &#34;&#34;&#34;Calculate the standardized residuals.&#34;&#34;&#34;

#...    If we haven&#39;t already done the metric calculations for these params,
#...    do them.
        if (params != () and params != self.pars):
            # print &#34;Calling margStats.&#34;
            self.calc_marg_stats(*params)

#...    Subtract projection from data.
        model = sum(self.ampl[:,newaxis]*self.modvals, 0)
        return self.std_smpls - model</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="inference.gauss.vecba.BA.amplitudes"><code class="name flex">
<span>def <span class="ident">amplitudes</span></span>(<span>self, *params)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the best-fit amplitudes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">    def amplitudes(self, *params):
        &#34;&#34;&#34;Calculate the best-fit amplitudes.&#34;&#34;&#34;

#...    If we haven&#39;t already done the metric calculations for these params,
#...    do them.
        if params != () and params != self.pars:
            # print &#34;Calling margStats.&#34;
            self.calc_marg_stats(*params)

#...    Now just return the stored amplitudes..
        return self.ampl</code></pre>
</details>
</dd>
<dt id="inference.gauss.vecba.BA.calc_marg_stats"><code class="name flex">
<span>def <span class="ident">calc_marg_stats</span></span>(<span>self, *params)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the marginal density and Jacobian vs. nonlinear parameters
and memoize the results.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">    def calc_marg_stats(self, *params):
        &#34;&#34;&#34;
        Calculate the marginal density and Jacobian vs. nonlinear parameters
        and memoize the results.
        &#34;&#34;&#34;

        if (params == self.pars):
            return self.Q, self.suf, self.Jac

#...    Evaluate the standardized models on the data, first calling the setup
#...    function for the data if it is present.
        args = list(params)
        args.append(self.absc)
        args = tuple(args)
        if (self.setup != None):
            aux = self.setup(*args)
            args = list(args)
            args.append(aux)
            args = tuple(args)
        for a in range(self.M):
            g = self.basis[a]
            self.modvals[a,:] = g(*args) / self.sigs

#...    Calculate the metric and various derived quantities.  Store them
#...    for possible future use before returning.
        self.metric, self.L, self.Jac, self.proj, self.ampl, self.suf =\
            vba.metricAnalysis(self.modvals, self.std_smpls)
        self.Q = self.dsqr - self.suf
        self.pars = params
        self.Jac = 1. / self.Jac</code></pre>
</details>
</dd>
<dt id="inference.gauss.vecba.BA.covar"><code class="name flex">
<span>def <span class="ident">covar</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the covariance matrix for the best-fit amplitudes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">    def covar(self):
        &#34;&#34;&#34;Return the covariance matrix for the best-fit amplitudes.&#34;&#34;&#34;

        global FIRSTTIME
        if FIRSTTIME:
            print(&#39;*** BA method covar is UNTESTED ***&#39;)  # Copied from old version--likely ok.
            FIRSTTIME = False

#...    If we haven&#39;t already done the metric calculations, complain!
        if self.pars == None:
            raise ValueError(&#39;Must calculate marginal first!&#39;)

        return vba.covar(self.L)</code></pre>
</details>
</dd>
<dt id="inference.gauss.vecba.BA.marg_stats"><code class="name flex">
<span>def <span class="ident">marg_stats</span></span>(<span>self, *params)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the quadratic form, sufficient statistic, and Jacobian as a
function of the passed nonlinear parameters.
These statistics allow
calculation of the marginal density for the nonlinear parameters, and
other inferences.</p>
<h2 id="returns">Returns</h2>
<p>Q - quadratic form (sum of squared residuals)
suf - sufficient statistic
Jac - Jacobian determinant
Let dsqr be the sum of squares of the standardized sample values; then
Q and suf are related, Q = dsqr - suf.</p>
<p>The log marginal likelihood for the nonlinear parameters is
-0.5*Q + log(J).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def marg_stats(self, *params):
    &#34;&#34;&#34;
    Return the quadratic form, sufficient statistic, and Jacobian as a
    function of the passed nonlinear parameters.  These statistics allow
    calculation of the marginal density for the nonlinear parameters, and
    other inferences.

    Returns:
        Q - quadratic form (sum of squared residuals)
        suf - sufficient statistic
        Jac - Jacobian determinant

    Let dsqr be the sum of squares of the standardized sample values; then
    Q and suf are related, Q = dsqr - suf.

    The log marginal likelihood for the nonlinear parameters is
    -0.5*Q + log(J).
    &#34;&#34;&#34;
    self.calc_marg_stats(*params)
    return self.Q, self.suf, self.Jac</code></pre>
</details>
</dd>
<dt id="inference.gauss.vecba.BA.residuals"><code class="name flex">
<span>def <span class="ident">residuals</span></span>(<span>self, *params)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the standardized residuals.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">    def residuals(self, *params):
        &#34;&#34;&#34;Calculate the standardized residuals.&#34;&#34;&#34;

#...    If we haven&#39;t already done the metric calculations for these params,
#...    do them.
        if (params != () and params != self.pars):
            # print &#34;Calling margStats.&#34;
            self.calc_marg_stats(*params)

#...    Subtract projection from data.
        model = sum(self.ampl[:,newaxis]*self.modvals, 0)
        return self.std_smpls - model</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="inference.gauss.vecba.BAObj"><code class="flex name class">
<span>class <span class="ident">BAObj</span></span>
<span>(</span><span>obj)</span>
</code></dt>
<dd>
<div class="desc"><p>Implement the Bretthorst algorithm using an object that provides basis
function and data access through these methods and attributes:</p>
<pre><code>set_nonlin(*args) - set the nonlinear parameters
std_smpls[i] - value of the i'th standardized sample
std_basis[k] - method returning 1-D array of standardized predictions
    from basis function k when called as std_basis[k]()
</code></pre>
<p>Initialize:
Specify number of basis functions, number of data samples,
and the object providing basis and data access.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BAObj:
    &#34;&#34;&#34;
    Implement the Bretthorst algorithm using an object that provides basis
    function and data access through these methods and attributes:

        set_nonlin(*args) - set the nonlinear parameters
        std_smpls[i] - value of the i&#39;th standardized sample
        std_basis[k] - method returning 1-D array of standardized predictions
            from basis function k when called as std_basis[k]()
    &#34;&#34;&#34;

    def __init__(self, obj):
        &#34;&#34;&#34;
        Initialize:  Specify number of basis functions, number of data samples,
        and the object providing basis and data access.
        &#34;&#34;&#34;

#...    Basic member data.
        self.obj = obj
        self.M = len(obj.std_basis)
        self.N = len(obj.std_smpls)
        self.dsqr = sum(obj.std_smpls*obj.std_smpls)

#...    We&#39;ll memoize the current params &amp; results to avoid duplicating work.
        self.pars = None
        self.suf = None
        self.Q = None
        self.Jac = None

#...    Space for model values (aka the design matrix).
        self.modvals = zeros((self.M, self.N), float)

    def marg_stats(self, *params):
        &#34;&#34;&#34;
        Return the quadratic form, sufficient statistic, and Jacobian as a
        function of the passed nonlinear parameters.  These statistics allow
        calculation of the marginal density for the nonlinear parameters, and
        other inferences.

        Returns:
            Q - quadratic form (sum of squared residuals)
            suf - sufficient statistic
            Jac - Jacobian determinant

        Let dsqr be the sum of squares of the standardized sample values; then
        Q and suf are related, Q = dsqr - suf.

        If the prior for the amplitudes is taken to be flat and independent of
        the nonlinear parameters, the log marginal likelihood for the nonlinear
        parameters is
            -0.5*Q + log(Jac)
        However, if a subset of the basis functions becomes (nearly)
        degenerate for some choice of the nonlinear parameters, the likelihood
        becomes constant in one or more directions, and the marginal
        likelihood for that choice of nonlinear parameters will diverge
        because the amplitude integral diverges.  One way to guard against
        this is to make the amplitude prior *depend on the nonlinear
        parameters* proportionally to the volume element in sample space
        spanned by the basis.  Then nonlinear parameter values that cause
        &#34;basis collapse&#34; are penalized (the prior density vanishes for them).
        This corresponds to a prior for the amplitudes proportional to Jac, so
        the log marginal likelihood for the nonlinear parameters is then
            -0.5*Q
        &#34;&#34;&#34;
        self.calc_marg_stats(*params)
        return self.Q, self.suf, self.Jac

    def calc_marg_stats(self, *params):
        &#34;&#34;&#34;
        Calculate the marginal density and Jacobian vs. nonlinear parameters
        and memoize the results.
        &#34;&#34;&#34;

        if (params == self.pars):
            return self.Q, self.suf, self.Jac

#...    Evaluate the standardized models on the data, first calling the setup
#...    function.
        self.obj.set_nonlin(*params)
        for a in range(self.M):
            self.modvals[a,:] = self.obj.std_basis[a]()

#...    Calculate the metric and various derived quantities.  Store them
#...    for possible future use before returning.
        self.metric, self.L, self.Jac, self.proj, self.ampl, self.suf =\
            vba.metricAnalysis(self.modvals, self.obj.std_smpls)
        self.Q = self.dsqr - self.suf
        self.pars = params
        self.Jac = 1. / self.Jac

    def amplitudes(self, *params):
        &#34;&#34;&#34;Calculate the best-fit amplitudes.&#34;&#34;&#34;

#...    If we haven&#39;t already done the metric calculations for these params,
#...    do them.
        if params != () and params != self.pars:
            # print &#34;Calling margStats.&#34;
            self.calc_marg_stats(*params)

#...    Now just return the stored amplitudes.
        return self.ampl

    def covar(self):
        &#34;&#34;&#34;Return the covariance matrix for the best-fit amplitudes.&#34;&#34;&#34;

        global FIRSTTIME
        if FIRSTTIME:
            print(&#39;*** BA method covar is UNTESTED ***&#39;)  # Copied from old version--likely ok.
            FIRSTTIME = False

#...    If we haven&#39;t already done the metric calculations, complain!
        if self.pars == None:
            raise ValueError(&#39;Must calculate marginal first!&#39;)
        return vba.covar(self.L)

    def residuals(self, *params):
        &#34;&#34;&#34;Calculate the standardized residuals.&#34;&#34;&#34;

#...    If we haven&#39;t already done the metric calculations for these params,
#...    do them.
        if (params != () and params != self.pars):
            # print &#34;Calling margStats.&#34;
            self.calc_marg_stats(*params)

#...    Subtract projection from data.
        model = sum(self.ampl[:,newaxis]*self.modvals, 0)
        return self.obj.std_smpls - model</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="inference.gauss.vecba.BAObj.amplitudes"><code class="name flex">
<span>def <span class="ident">amplitudes</span></span>(<span>self, *params)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the best-fit amplitudes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">    def amplitudes(self, *params):
        &#34;&#34;&#34;Calculate the best-fit amplitudes.&#34;&#34;&#34;

#...    If we haven&#39;t already done the metric calculations for these params,
#...    do them.
        if params != () and params != self.pars:
            # print &#34;Calling margStats.&#34;
            self.calc_marg_stats(*params)

#...    Now just return the stored amplitudes.
        return self.ampl</code></pre>
</details>
</dd>
<dt id="inference.gauss.vecba.BAObj.calc_marg_stats"><code class="name flex">
<span>def <span class="ident">calc_marg_stats</span></span>(<span>self, *params)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the marginal density and Jacobian vs. nonlinear parameters
and memoize the results.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">    def calc_marg_stats(self, *params):
        &#34;&#34;&#34;
        Calculate the marginal density and Jacobian vs. nonlinear parameters
        and memoize the results.
        &#34;&#34;&#34;

        if (params == self.pars):
            return self.Q, self.suf, self.Jac

#...    Evaluate the standardized models on the data, first calling the setup
#...    function.
        self.obj.set_nonlin(*params)
        for a in range(self.M):
            self.modvals[a,:] = self.obj.std_basis[a]()

#...    Calculate the metric and various derived quantities.  Store them
#...    for possible future use before returning.
        self.metric, self.L, self.Jac, self.proj, self.ampl, self.suf =\
            vba.metricAnalysis(self.modvals, self.obj.std_smpls)
        self.Q = self.dsqr - self.suf
        self.pars = params
        self.Jac = 1. / self.Jac</code></pre>
</details>
</dd>
<dt id="inference.gauss.vecba.BAObj.covar"><code class="name flex">
<span>def <span class="ident">covar</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the covariance matrix for the best-fit amplitudes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">    def covar(self):
        &#34;&#34;&#34;Return the covariance matrix for the best-fit amplitudes.&#34;&#34;&#34;

        global FIRSTTIME
        if FIRSTTIME:
            print(&#39;*** BA method covar is UNTESTED ***&#39;)  # Copied from old version--likely ok.
            FIRSTTIME = False

#...    If we haven&#39;t already done the metric calculations, complain!
        if self.pars == None:
            raise ValueError(&#39;Must calculate marginal first!&#39;)
        return vba.covar(self.L)</code></pre>
</details>
</dd>
<dt id="inference.gauss.vecba.BAObj.marg_stats"><code class="name flex">
<span>def <span class="ident">marg_stats</span></span>(<span>self, *params)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the quadratic form, sufficient statistic, and Jacobian as a
function of the passed nonlinear parameters.
These statistics allow
calculation of the marginal density for the nonlinear parameters, and
other inferences.</p>
<h2 id="returns">Returns</h2>
<p>Q - quadratic form (sum of squared residuals)
suf - sufficient statistic
Jac - Jacobian determinant
Let dsqr be the sum of squares of the standardized sample values; then
Q and suf are related, Q = dsqr - suf.</p>
<p>If the prior for the amplitudes is taken to be flat and independent of
the nonlinear parameters, the log marginal likelihood for the nonlinear
parameters is
-0.5<em>Q + log(Jac)
However, if a subset of the basis functions becomes (nearly)
degenerate for some choice of the nonlinear parameters, the likelihood
becomes constant in one or more directions, and the marginal
likelihood for that choice of nonlinear parameters will diverge
because the amplitude integral diverges.
One way to guard against
this is to make the amplitude prior </em>depend on the nonlinear
parameters<em> proportionally to the volume element in sample space
spanned by the basis.
Then nonlinear parameter values that cause
"basis collapse" are penalized (the prior density vanishes for them).
This corresponds to a prior for the amplitudes proportional to Jac, so
the log marginal likelihood for the nonlinear parameters is then
-0.5</em>Q</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def marg_stats(self, *params):
    &#34;&#34;&#34;
    Return the quadratic form, sufficient statistic, and Jacobian as a
    function of the passed nonlinear parameters.  These statistics allow
    calculation of the marginal density for the nonlinear parameters, and
    other inferences.

    Returns:
        Q - quadratic form (sum of squared residuals)
        suf - sufficient statistic
        Jac - Jacobian determinant

    Let dsqr be the sum of squares of the standardized sample values; then
    Q and suf are related, Q = dsqr - suf.

    If the prior for the amplitudes is taken to be flat and independent of
    the nonlinear parameters, the log marginal likelihood for the nonlinear
    parameters is
        -0.5*Q + log(Jac)
    However, if a subset of the basis functions becomes (nearly)
    degenerate for some choice of the nonlinear parameters, the likelihood
    becomes constant in one or more directions, and the marginal
    likelihood for that choice of nonlinear parameters will diverge
    because the amplitude integral diverges.  One way to guard against
    this is to make the amplitude prior *depend on the nonlinear
    parameters* proportionally to the volume element in sample space
    spanned by the basis.  Then nonlinear parameter values that cause
    &#34;basis collapse&#34; are penalized (the prior density vanishes for them).
    This corresponds to a prior for the amplitudes proportional to Jac, so
    the log marginal likelihood for the nonlinear parameters is then
        -0.5*Q
    &#34;&#34;&#34;
    self.calc_marg_stats(*params)
    return self.Q, self.suf, self.Jac</code></pre>
</details>
</dd>
<dt id="inference.gauss.vecba.BAObj.residuals"><code class="name flex">
<span>def <span class="ident">residuals</span></span>(<span>self, *params)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the standardized residuals.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">    def residuals(self, *params):
        &#34;&#34;&#34;Calculate the standardized residuals.&#34;&#34;&#34;

#...    If we haven&#39;t already done the metric calculations for these params,
#...    do them.
        if (params != () and params != self.pars):
            # print &#34;Calling margStats.&#34;
            self.calc_marg_stats(*params)

#...    Subtract projection from data.
        model = sum(self.ampl[:,newaxis]*self.modvals, 0)
        return self.obj.std_smpls - model</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="inference.gauss" href="index.html">inference.gauss</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="inference.gauss.vecba.BA" href="#inference.gauss.vecba.BA">BA</a></code></h4>
<ul class="">
<li><code><a title="inference.gauss.vecba.BA.amplitudes" href="#inference.gauss.vecba.BA.amplitudes">amplitudes</a></code></li>
<li><code><a title="inference.gauss.vecba.BA.calc_marg_stats" href="#inference.gauss.vecba.BA.calc_marg_stats">calc_marg_stats</a></code></li>
<li><code><a title="inference.gauss.vecba.BA.covar" href="#inference.gauss.vecba.BA.covar">covar</a></code></li>
<li><code><a title="inference.gauss.vecba.BA.marg_stats" href="#inference.gauss.vecba.BA.marg_stats">marg_stats</a></code></li>
<li><code><a title="inference.gauss.vecba.BA.residuals" href="#inference.gauss.vecba.BA.residuals">residuals</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="inference.gauss.vecba.BAObj" href="#inference.gauss.vecba.BAObj">BAObj</a></code></h4>
<ul class="">
<li><code><a title="inference.gauss.vecba.BAObj.amplitudes" href="#inference.gauss.vecba.BAObj.amplitudes">amplitudes</a></code></li>
<li><code><a title="inference.gauss.vecba.BAObj.calc_marg_stats" href="#inference.gauss.vecba.BAObj.calc_marg_stats">calc_marg_stats</a></code></li>
<li><code><a title="inference.gauss.vecba.BAObj.covar" href="#inference.gauss.vecba.BAObj.covar">covar</a></code></li>
<li><code><a title="inference.gauss.vecba.BAObj.marg_stats" href="#inference.gauss.vecba.BAObj.marg_stats">marg_stats</a></code></li>
<li><code><a title="inference.gauss.vecba.BAObj.residuals" href="#inference.gauss.vecba.BAObj.residuals">residuals</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>